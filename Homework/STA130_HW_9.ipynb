{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Coding Homework 9: [put your name here]\n",
    "\n",
    "Go through this notebook, following the instructions! (Remember to not delete or create any cells)\n",
    "\n",
    "> TAs will mark this assignment by checking ***MarkUs*** autotests and by manually grading Q12.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "We begin by importing dataset and the libraries we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree, model_selection\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import graphviz as gv\n",
    "happiness2017 = pd.read_csv(\"happiness2017.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Gallup Report Happiness Survey\n",
    "Using data from the Gallup World Poll (and the World Happiness Report), we are interested in predicting which factors influence life expectancy around the world. These data are in the file happinessdata_2017.csv, which we imported as `happiness2017`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Q1: Add a new column to `happiness2017` called `life_exp_good` which is `True` for countries with life expectancy higher than 65 years, and `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: your answer will be tested!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Now divide create a new dataframe `happiness2017_cleaned` from `happiness2017` that contains the following columns `life_exp_good`, `logGDP`, `social_support`, `freedom`, and `generosity`, with all rows with `NaN` entries dropped. Then create an 80/20 split (80% training set and 20% testing set) for the `happiness2017_cleaned` data.\n",
    "\n",
    "- To do this in a reproducible way, we're going to set a \"random seed\"; and, in preparation for this, let's take a moment to motivate our choice of $1985$ for the \"random seed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# 19, 19, 1985!\n",
    "YouTubeVideo('K38xNqZvBJI', width=800, height=500)\n",
    "# Remember, always choose your favorite number for your \"random seeds\"\n",
    "# The specific number you choose doesn't even really matter, which is why \n",
    "# it's so important to make a big deal about it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Data_Split",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1985) # do NOT change this line: it sets the \"random number generation seed\"\n",
    "# which makes the \"pseudorandomness\" gererated in the code the same every time and this\n",
    "# makes the code reproducibile which ensures that our testing code works properly every time\n",
    "happiness2017_cleaned = None\n",
    "train, test = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Q2: Train a classification tree `clf` using only the  `social_support` variable to predict if a country has good life expectancy\n",
    "\n",
    "#### Use default values for all (tuning) parameters instantiating the Decision Tree Classifier.\n",
    "\n",
    "> Hint: should you use the `train` data, or the `test` data, or all this data combined to fit the classification tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: your answer will be tested!\n",
    "np.random.seed(1985) #Do not change this line\n",
    "clf = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Now you can visualize your tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tree.plot_tree(clf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Or to make it look prettier we can use graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                feature_names=[\"social_support\"],\n",
    "                                class_names=[\"Good\", \"Bad\"],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = gv.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And to make it legible we can add the max_depth parameter to our call of export_graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None, max_depth=3,\n",
    "                                feature_names=[\"social_support\"],\n",
    "                                class_names=[\"Good\", \"Bad\"],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = gv.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Q3: How many observation are in the training data set and the test data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q3 empty cell",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Q3: your answer will be tested!\n",
    "num_train = None # Replace this with the number of observations in the training set\n",
    "num_test = None # Replace this with the number of observations in the test set\n",
    "Q3 = (num_train, num_test) # Do not change this line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Q4: Why did you fit the classification tree with the data set you did?\n",
    "\n",
    "#### Write a one to two sentence answer to this question in markdown cell below\n",
    "- Compare your response to the answer given in the ***MarkUs*** output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "> Answer here...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Q5: Comment on the complexity of the decision tree classification model visualized above, especially in light of the fact that only a single feature was used to predict the outcome in this model.\n",
    "\n",
    "\n",
    "#### Write a one to two sentence answer to this question in markdown cell below\n",
    "- Compare your response to the answer given in the ***MarkUs*** output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "> Answer here...\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Q6: Use the `clf.predict()` method to answer the following questions and confirm your answer using the `graphviz` visualization of the decision tree\n",
    "a) Does your decision tree predict that a country with `social_support = .49` has good life expectancy?  \n",
    "b) what if `social_support = .5`  \n",
    "c) what if `social_support = .51`  \n",
    "d) what if `social_support = .9`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: your answer will be tested!\n",
    "Q6a = None # Replace this with True or False: don't supply something like array([False])\n",
    "Q6b = None\n",
    "Q6c = None\n",
    "Q6d = None\n",
    "Q6 = (Q6a, Q6b, Q6c, Q6d) # Do not change this line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Do these predictions make sense to you?\n",
    "\n",
    "Look at how these small differences in the input rapidly change the predicted label... it seems kind of strange. It's a little hard to intuitively see why predictions should change like this... it makes you wonder if the model is really doing anything meaningful here.  \n",
    "\n",
    "Perhaps the model might just actually be overly complex and convoluted and might be overinterpreting the data used to fit it (which we call overfitting). Since you'll probably agree that the behaviour of the model that we're observing seems a bit off, you'll probably also agree that it's a reasonable idea to try reduce the complexity of the model so it can be more reliably estimated with the data at hand.  With that in mind, create and fit a new classification tree `clf2` on the same inputs with a maximum depth of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clf2 creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1985) #Do not change this line\n",
    "clf2 = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Q7: Reanswer Q6 with `clf2`.\n",
    "\n",
    "#### Use the same train/test split data used so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: your answer will be tested!\n",
    "Q7a = None # Replace this with True or False\n",
    "Q7b = None\n",
    "Q7c = None\n",
    "Q7d = None\n",
    "Q7 = (Q7a, Q7b, Q7c, Q7d) # Do not change this line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Now train another classification tree `clf3` using `logGDP`, `social_support`, `freedom`, and `generosity` as potential predictors.\n",
    "\n",
    "#### Use the same train/test split data used so far and use default (tuning) parameters when instantiating the model (so, e.g., don't set a maximum tree depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clf3 creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1985) #Do not change this line\n",
    "clf3 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf3, out_file=None, max_depth= 3,\n",
    "                                feature_names=[\"logGDP\", \"social_support\", \"freedom\", \"generosity\"],\n",
    "                                class_names=[\"Good\", \"Bad\"],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = gv.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Q8: Use the testing dataset you created in Q1 to create confusion matrices for `clf2` and `clf3`. Report the sensitivity (true positive rate), specificity (true negative rate) and accuracy for each of the trees/models.\n",
    "\n",
    "\n",
    "#### Provide your answers as decimal numbers with three signifiant digits, such as `0.123` (and not as percentages like `12.3%`), and treat “Good” life expectancy as the positive response and prediction class. \n",
    "\n",
    "> Hint 1: Use `np.round(0.1234,3)` to produce the correct rouding for the answers  \n",
    "> Hint 2: `y_true` or `y_pred` parameter go first in the `confusion_matrix` function?  \n",
    "> Hint 3: Which columns/features of the `test` data set should be used for `clf2` versus `clf3`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q8 empty cell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: your answer will be tested!\n",
    "(clf2_sensitivity, clf2_specificity, clf2_accuracy) = (None, None, None) #Replace the Nones with the corresponding answers\n",
    "(clf3_sensitivity, clf3_specificity, clf3_accuracy) = (None, None, None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature importance\n",
    "As we are statisticians in this course, the extent to which we do not understand the internal workings and predictions from our decision trees depend on the predictor variables should feel a bit off-putting. To remedy this we can use heuristics to judge how relatively important the different predictor variables are. For our purposes the simplest heuristic we can use is the Gini Importance: the gini importance of a predicting variable X is defined as the number of nodes which split on X divided by the total number of splits in the tree.  You can find the gini importances from a classification tree using `.feature_importances_`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Q9: Which predictor variable is most important for making predictions according to clf3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q9_empty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Q9: your answer will be tested!\n",
    "Q9 = None # Replace this with the name of the most relevant predictor variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Q10: Describe the differences/similarities of interpreting coefficients in linear model regression versus feature importances in decision trees.\n",
    "#### Write a 1-2 sentence answer to this question in markdown cell below\n",
    "- Compare your response to the answer given in the ***MarkUs*** output.\n",
    "\n",
    "Hint: Consider the differing goals of linear regression and classification trees."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "# Confusion matrices and Metrics\n",
    "Accuracy is the proportion of cases that are correctly identified.\n",
    "Sensitivity, also known as true positive rate (TPR), is the proportion of actual positive cases which are correctly identified to be positive (i.e. are true positives).\n",
    "Specificity, also known as true negative rate (TNR), is the proportion of actual negative cases which are correctly identified to be negative (i.e. are true negative).\n",
    "False positive/negative rates are defined to be the proportion of actual positive/negative cases which are incorrectly identified.\n",
    "In formulas,\n",
    "$$ Accuracy = (TP+TN)/\\text{total \\# of cases}$$\n",
    "$$ TPR = TP/(TP+FN) = 1-FNR$$\n",
    "$$ TNR = TN/(TN+FP) = 1-FPR$$\n",
    "You can read more and see a handy list of formulas at the following [wikipedia page.](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Two classification trees were built to predict which individuals have a disease using different sets of potential predictors. We use each of these trees to predict disease status for 100 new individuals. Below are confusion matrices corresponding to these two classification trees. The columns are the actual outcome, the rows are predicted outcomes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| **Tree A**         | Disease | No disease | $\\hspace{1in}$ | **Tree B**         | Disease | No disease |\n",
    "|--------------------|---------|------------|----------------|--------------------|---------|------------|\n",
    "| Predict disease    | 36      | 22         |                | Predict disease    | 24      | 6          |\n",
    "| Predict no disease | 2       | 40         |                | Predict no disease | 14      | 56         |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### Q11: Calculate the accuracy, false-positive rate, and false negative rate for each classification tree.\n",
    "Here, a “positive” result means we predict an individual has the disease and a “negative” result means we predict they do not.\n",
    "Round each value to 2 decimal points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11: your answer will be tested!\n",
    "TreeA_accuracy = None\n",
    "TreeA_false_positive_rate = None\n",
    "TreeA_false_negative_rate = None\n",
    "\n",
    "TreeB_accuracy = None\n",
    "TreeB_false_positive_rate = None\n",
    "TreeB_false_negative_rate = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Q12: Which tree would you prefer to put into use in predicting if individuals are ill?\n",
    "#### Write a 1-3 sentence answer to this question in markdown cell below.\n",
    "- This question will be manually graded by TAs. They are **not** looking for a specific answer, any well written answer is acceptable.\n",
    "- You can see the **MarkUs** output for some ideas.\n",
    "\n",
    "Hint 1: Make reference to the metrics you calculated in Q10, and any others you think might matter.\n",
    "Hint 2: Interpret what the metrics mean in the context of the problem before deciding how much the metrics matter to you.\n",
    "Hint 3: What tradeoffs might you find acceptable vs. unacceptable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "# Geometric Interpretation of Prediction\n",
    "Data was collected on 30 cancer patients to investigate the effectiveness (Yes/No) of a treatment. Two quantitative variables x1 and x2 (taking values between 0 and 1) are thought to be important predictors of effectiveness. Suppose that the rectangles labeled as nodes in the scatter plot below represent nodes of a classification tree.\n",
    "![Scatter plot with a horizontal x1 axis and vertical x2 axis, both ranging from 0.00 to 1.00, and blue triangular points representing Effectiveness = 'Yes' and round orange points representing Effectiveness = 'No'. It is divided into 4 regions, labelled nodes 1-4. Node 1 is the bottom left region, node 4 the bottom right, node 3 the top left, and node 2 the top right. The top regions are divided from the bottom ones by a horizontal line along x_2=0.50. Node 2 is separated from node 3 by a line at x1=0.50. Node 2 is separated from node 3 by a line at x1=0.50. Node 1 has 5 'Yes' nodes and 7 'No' Nodes. Node 2 has 3 'Yes' nodes and 2 'No' Nodes. Node 3 has 1 'Yes' node and 3 'No' Nodes. Node 4 has 2 'Yes' nodes and 7 'No' Nodes.](HW9_Q7_Graph.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Q13: The diagram above is the geometric interpretation of a classification tree to predict drug effectiveness based on two predictors, x1 and x2. What is the predicted class of each node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13: your answer will be tested!\n",
    "Q13_Node1 = None #Replace with 'Yes' or 'No'\n",
    "Q13_Node2 = None\n",
    "Q13_Node3 = None\n",
    "Q13_Node4 = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Q14: What is the first variable that the decision tree splits on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q14",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Q14: your answer will be tested!\n",
    "Q14 = None # Replace with 'x1' or 'x2'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
