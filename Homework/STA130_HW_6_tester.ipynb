{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa1e99a5",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Coding Homework 6: [Your Name]\n",
    "\n",
    "Go through this notebook, following the instructions! \n",
    "\n",
    "- You can add new cells if you need (with the \\\"+\\\" button above); but, deleting cells could very likely cause your notebook to fail MarkUs autotesting (and you'd have to start over and re-enter your answers into a completely fresh version of the notebook to get things to work again...)\n",
    "\n",
    "> TAs will mark this assignment by first checking ***MarkUs*** autotests for completion and general correctness, and then manually reviewing your written response to `Q16` and `Q20` and quickly double checking for the presense of plotted figures for `Q2`, `Q17` and `Q18`.\n",
    "> - The  `Q0, Q2, Q4, Q16` questions \"automatically fail\" during automated testing so that MarkUs exposes example answers for student review and consideration for these problems: these \"failed MarkUs tests\" are not counted against the student.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb0423",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Social Media and Anxiety\n",
    "\n",
    "There have been many questions regarding whether or not social media usage increases anxiety levels. For example, do  TikTok and Facebook posts create an unattainable sense of life success and satisfaction?  Does procrastinating by watching YouTube videos or reading Twitter posts contribute unnecessary stress from deadline pressure? A study was conducted to examine the relationship between social media usage and student anxiety. Students were asked to categorize their social media usage as \"High\" if it exceeded more than 2 hours per day, and then student anxiety levels where scored through as series of questions, with higher scores suggesting higher student anxiety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68cc11e2",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anxiety_scores</th>\n",
       "      <th>social_media_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.64</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.29</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.32</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.83</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.02</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33.31</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.60</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.13</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.69</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28.90</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26.43</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24.23</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.10</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32.86</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21.06</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28.89</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28.71</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31.73</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30.02</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21.96</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25.49</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>38.81</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27.85</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30.29</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30.72</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>21.43</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>22.24</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11.12</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30.86</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.92</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>33.57</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>34.09</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>27.63</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>31.26</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35.91</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>26.68</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>29.49</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>35.32</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>26.24</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>32.34</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>31.34</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>33.53</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>27.62</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>42.91</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>30.20</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>32.54</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    anxiety_scores social_media_usage\n",
       "0            24.64                Low\n",
       "1            39.29                Low\n",
       "2            16.32                Low\n",
       "3            32.83                Low\n",
       "4            28.02                Low\n",
       "5            33.31                Low\n",
       "6            20.60                Low\n",
       "7            21.13                Low\n",
       "8            26.69                Low\n",
       "9            28.90                Low\n",
       "10           26.43                Low\n",
       "11           24.23                Low\n",
       "12            7.10                Low\n",
       "13           32.86                Low\n",
       "14           21.06                Low\n",
       "15           28.89                Low\n",
       "16           28.71                Low\n",
       "17           31.73                Low\n",
       "18           30.02                Low\n",
       "19           21.96                Low\n",
       "20           25.49                Low\n",
       "21           38.81                Low\n",
       "22           27.85                Low\n",
       "23           30.29                Low\n",
       "24           30.72                Low\n",
       "25           21.43                Low\n",
       "26           22.24                Low\n",
       "27           11.12                Low\n",
       "28           30.86                Low\n",
       "29           19.92                Low\n",
       "30           33.57               High\n",
       "31           34.09               High\n",
       "32           27.63               High\n",
       "33           31.26               High\n",
       "34           35.91               High\n",
       "35           26.68               High\n",
       "36           29.49               High\n",
       "37           35.32               High\n",
       "38           26.24               High\n",
       "39           32.34               High\n",
       "40           31.34               High\n",
       "41           33.53               High\n",
       "42           27.62               High\n",
       "43           42.91               High\n",
       "44           30.20               High\n",
       "45           32.54               High"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# The `numpy.repeat` function replicates elements as demonstrated here\n",
    "social_media_usage = np.repeat([\"Low\", \"High\"], [30, 16])\n",
    "anxiety_scores = [24.64, 39.29, 16.32, 32.83, 28.02, \n",
    "                   33.31, 20.60, 21.13, 26.69, 28.90,\n",
    "                   26.43, 24.23, 7.10,  32.86, 21.06,\n",
    "                   28.89, 28.71, 31.73, 30.02, 21.96,\n",
    "                   25.49, 38.81, 27.85, 30.29, 30.72,\n",
    "                   21.43, 22.24, 11.12, 30.86, 19.92,\n",
    "                   33.57, 34.09, 27.63, 31.26,\n",
    "                   35.91, 26.68, 29.49, 35.32,\n",
    "                   26.24, 32.34, 31.34, 33.53,\n",
    "                   27.62, 42.91, 30.20, 32.54]\n",
    "anxiety_data = pd.DataFrame({'anxiety_scores': anxiety_scores, 'social_media_usage': social_media_usage})\n",
    "anxiety_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7e5b9",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q0: In simple terms, what is the claim of the *null hypothesis* for the experiment above that we are naturally trying to provide evidence against? How could this be formally stated with respect to the parameters $Median_{High}$ and $Median_{Low}$ of the two populations in question? And what is $H_1$ in terms of $H_0$?\n",
    "\n",
    "#### Provide your written answer in the markdown cell below.\n",
    "- You can compare your answer with the example solution provided by MarkUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e73e0",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Hint: In two-sample contexts the *null hypotheses* tends to be the most natural form of a \"no effect\" statement that \"nothing interesting or notable is happening\"; and, it's generally a \"straw man\" that we're trying to provide enough evidence against to reject. For example, a formal *null hypotheses* that there is no difference in the means of two groups would be $H_0: \\mu_{High} = \\mu_{Low}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af87b2b",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b09d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\nIncluded as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += \"The natural null hypothesis here is that social media usage does not affect stress, \\n\"\n",
    "hint += \"because this is the idea (null hypothesis) we'd like to provide evidence against. \\n\"\n",
    "hint += \"Formally, for \\\"High\\\" social media usage population H \\nand \\\"Low\\\" social media usage population L with medians \\n\"\n",
    "hint += \"$\\\\text{50\\%}_{\\\\text{H}}$ and $\\\\text{50\\%}_{\\\\text{L}}$, respectively, \\n\"\n",
    "hint += \"the null and alternative hypothesis in LaTeX are\\n\"\n",
    "hint += '''\n",
    "$\n",
    "H_0: \\\\text{50\\%}_{\\\\text{H}} = \\\\text{50\\%}_{\\\\text{L}} \\\\\\\\\n",
    "H_1: H_0 \\\\text{ is false } (\\\\text{50\\%}_{\\\\text{H}} \\\\neq \\\\text{50\\%}_{\\\\text{L}})\n",
    "$\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b68ab7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nThe natural null hypothesis here is that social media usage does not affect stress, \nbecause this is the idea (null hypothesis) we'd like to provide evidence against. \nFormally, for \"High\" social media usage population H \nand \"Low\" social media usage population L with medians \n$\\text{50\\%}_{\\text{H}}$ and $\\text{50\\%}_{\\text{L}}$, respectively, \nthe null and alternative hypothesis in LaTeX are\n\n$\nH_0: \\text{50\\%}_{\\text{H}} = \\text{50\\%}_{\\text{L}} \\\\\nH_1: H_0 \\text{ is false } (\\text{50\\%}_{\\text{H}} \\neq \\text{50\\%}_{\\text{L}})\n$\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q0\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: \n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nThe natural null hypothesis here is that social media usage does not affect stress, \nbecause this is the idea (null hypothesis) we'd like to provide evidence against. \nFormally, for \"High\" social media usage population H \nand \"Low\" social media usage population L with medians \n$\\text{50\\%}_{\\text{H}}$ and $\\text{50\\%}_{\\text{L}}$, respectively, \nthe null and alternative hypothesis in LaTeX are\n\n$\nH_0: \\text{50\\%}_{\\text{H}} = \\text{50\\%}_{\\text{L}} \\\\\nH_1: H_0 \\text{ is false } (\\text{50\\%}_{\\text{H}} \\neq \\text{50\\%}_{\\text{L}})\n$\n"
     ]
    }
   ],
   "source": [
    "# test_Q0\n",
    "assert False, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf8950",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q1: Revisit your statements regarding the *null hypotheses* above with \"confounding\" in mind; namely, since social media usage is a self-selecting process, perhaps social media users are already more anxious people on average regardless of their social media usage.  If we provide evidence about the *null hypotheses* are we actually addressing the question of \"whether or not usage of social media increases anxiety levels\"? Or are we just using a hypothesis test to examine if there is strong evidence of difference between the two groups (regardless of its causes)?  \n",
    "\n",
    "A. Neither, we are checking if confounding impacts our determination of \"whether or not usage of social media increases anxiety levels\"  \n",
    "B. We actually addressing the question of \"whether or not usage of social media increases anxiety levels\"   \n",
    "C. We are just using a hypothesis test to examine how strong the observable evidence of a difference between the two groups is (regardless of its causes)  \n",
    "D. None of the above: we cannot determine any of the above from a two-sample hypothesis test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef4a6a6",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q1: your answer will be tested!\n",
    "Q1 = None  # Assign either 'A' or 'B' or 'C' or 'D' to `Q1` instead of `None`\n",
    "# E.g., Q1 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff0c8a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"The null hypothesis is a statement of equivalence between the two groups,\\n\"\n",
    "hint += \"so a two-sample hypothesis might be able to provide evidence against the null hypothesis\\n\"\n",
    "hint += \"on the basis of an observable strong difference between the two groups, or fail to do so. \\n\"\n",
    "hint += \"The null hypothesis tells us nothing about any cause of a possible difference; however...\\n\\n\"\n",
    "hint += \"if we don't think there is any confounding, then the difference would be attributable to\\n\"\n",
    "hint += \"the remaining differences between the two groups...\\n\\n\"\n",
    "hint += \"Confounding of pre-existing differences between the two groups does seem like it might be\\n\"\n",
    "hint += \"possible, so that might explain differences; or, social media usage may indeed be what's\\n\"\n",
    "hint += \"really different between the two groups after all...\"\n",
    "\n",
    "test = Q1 == 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d64b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The null hypothesis is a statement of equivalence between the two groups,\nso a two-sample hypothesis might be able to provide evidence against the null hypothesis\non the basis of an observable strong difference between the two groups, or fail to do so. \nThe null hypothesis tells us nothing about any cause of a possible difference; however...\n\nif we don't think there is any confounding, then the difference would be attributable to\nthe remaining differences between the two groups...\n\nConfounding of pre-existing differences between the two groups does seem like it might be\npossible, so that might explain differences; or, social media usage may indeed be what's\nreally different between the two groups after all...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q1\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: The null hypothesis is a statement of equivalence between the two groups,\nso a two-sample hypothesis might be able to provide evidence against the null hypothesis\non the basis of an observable strong difference between the two groups, or fail to do so. \nThe null hypothesis tells us nothing about any cause of a possible difference; however...\n\nif we don't think there is any confounding, then the difference would be attributable to\nthe remaining differences between the two groups...\n\nConfounding of pre-existing differences between the two groups does seem like it might be\npossible, so that might explain differences; or, social media usage may indeed be what's\nreally different between the two groups after all..."
     ]
    }
   ],
   "source": [
    "# test_Q1\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6a5b2",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q2: Construct boxplots of `anxiety_score` for the two levels of social media usage, and write 2-3 sentences describing and comparing the distributions of anxiety scores across the social media usage groups.  \n",
    "#### Provide your written answer in the markdown cell below.\n",
    "- You can compare your answer with the example solution provided by MarkUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e8211ff",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Code your solution here\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae8370",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f0e7af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\n\"\n",
    "hint += \"Included as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += \"CODE:\\n\"\n",
    "hint += '''\n",
    "import plotly.express as px\n",
    "fig = px.box(anxiety_data, x='anxiety_scores', y = 'social_media_usage')\n",
    "fig.show()\n",
    "'''\n",
    "hint += \"\\n\\nWRITTEN SOLUTION:\\n\\n\"\n",
    "hint += \"A simple statement of the visual appearance of the comparison of the two groups\\n\" \n",
    "hint += \"is that they both appear to be roughtly symmetric, with the \\\"High\\\" group both\\n\"\n",
    "hint += \"shifted up to the right with higher scores and simultaneously more tightly\\n\"\n",
    "hint += \"centered around a higher average score compared to the \\\"Low\\\" group whose wider\\n\"\n",
    "hint += \"spread that extends both higher as well as quite a bit below the \\\"High\\\" group.\\n\\n\"\n",
    "hint += \"To give a little more detail...\\n\"\n",
    "hint += \"there indeed appears to be a clear difference in anxiety between \\\"Low\\\" and \\\"High\\\" \\n\"\n",
    "hint += \"social media usage groups, with the median of the \\\"High\\\" group exceeding the 75th \\n\"\n",
    "hint += \"percentile of the \\\"Low\\\" group.  For the \\\"High\\\" social media usage group, \\n\"\n",
    "hint += \"the anxiety scores are much more concentrated around high (>30) anxiety scores \\n\"\n",
    "hint += \"with a tighter spread; whereas, for the \\\"Low\\\" social media usage group, \\n\"\n",
    "hint += \"the anxiety scores are much more highly variable, with the upper 50% of the \\n\"\n",
    "hint += \"anxiety scores in the \\\"Low\\\" social media usage group overlapping or even \\n\"\n",
    "hint += \"exceeding some scores in the \\\"High\\\" social media usage group, but most \\n\"\n",
    "hint += \"of the lower 50% of anxiety scores in the \\\"Low\\\" social media usage group \\n\"\n",
    "hint += \"being less than all the scores in the \\\"High\\\" social media usage group.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce3022e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nCODE:\n\nimport plotly.express as px\nfig = px.box(anxiety_data, x='anxiety_scores', y = 'social_media_usage')\nfig.show()\n\n\nWRITTEN SOLUTION:\n\nA simple statement of the visual appearance of the comparison of the two groups\nis that they both appear to be roughtly symmetric, with the \"High\" group both\nshifted up to the right with higher scores and simultaneously more tightly\ncentered around a higher average score compared to the \"Low\" group whose wider\nspread that extends both higher as well as quite a bit below the \"High\" group.\n\nTo give a little more detail...\nthere indeed appears to be a clear difference in anxiety between \"Low\" and \"High\" \nsocial media usage groups, with the median of the \"High\" group exceeding the 75th \npercentile of the \"Low\" group.  For the \"High\" social media usage group, \nthe anxiety scores are much more concentrated around high (>30) anxiety scores \nwith a tighter spread; whereas, for the \"Low\" social media usage group, \nthe anxiety scores are much more highly variable, with the upper 50% of the \nanxiety scores in the \"Low\" social media usage group overlapping or even \nexceeding some scores in the \"High\" social media usage group, but most \nof the lower 50% of anxiety scores in the \"Low\" social media usage group \nbeing less than all the scores in the \"High\" social media usage group.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: \n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nCODE:\n\nimport plotly.express as px\nfig = px.box(anxiety_data, x='anxiety_scores', y = 'social_media_usage')\nfig.show()\n\n\nWRITTEN SOLUTION:\n\nA simple statement of the visual appearance of the comparison of the two groups\nis that they both appear to be roughtly symmetric, with the \"High\" group both\nshifted up to the right with higher scores and simultaneously more tightly\ncentered around a higher average score compared to the \"Low\" group whose wider\nspread that extends both higher as well as quite a bit below the \"High\" group.\n\nTo give a little more detail...\nthere indeed appears to be a clear difference in anxiety between \"Low\" and \"High\" \nsocial media usage groups, with the median of the \"High\" group exceeding the 75th \npercentile of the \"Low\" group.  For the \"High\" social media usage group, \nthe anxiety scores are much more concentrated around high (>30) anxiety scores \nwith a tighter spread; whereas, for the \"Low\" social media usage group, \nthe anxiety scores are much more highly variable, with the upper 50% of the \nanxiety scores in the \"Low\" social media usage group overlapping or even \nexceeding some scores in the \"High\" social media usage group, but most \nof the lower 50% of anxiety scores in the \"Low\" social media usage group \nbeing less than all the scores in the \"High\" social media usage group."
     ]
    }
   ],
   "source": [
    "# test_Q2\n",
    "assert False, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d71493",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q3: What do these data visually suggest regarding the claim that the ***median*** anxiety level is different for the population of people with high frequency social media use compared to the population with low frequency use? \n",
    "\n",
    "A. The median anxiety level is likely higher for low frequency social media users compared to higher frequency social media users.  \n",
    "B. We cannot say, since the groups are shuffled and we do not know the proportion of high frequency or lower frequency social media users in each group.    \n",
    "C. The median anxiety level is likely the same for low frequency social media users compared to higher frequency social media users.  \n",
    "D. The median anxiety level is likely higher for high frequency social media users compared to lower frequency social media users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21826f8b",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q3: your answer will be tested!\n",
    "Q3 = None  # Assign either 'A' or 'B' or 'C' or 'D' to `Q3` instead of `None`\n",
    "# E.g., Q3 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35c910ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"On each box in the boxplot, the left side is the 25th percentile, \\n\"\n",
    "hint += \"the middle line is the 50th percentile while the right side is the 75th percentile.\\n\"\n",
    "hint += \"Consider reviewing the answer to Q2 if this is not sufficiently helpful.\"\n",
    "test = Q3 == 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08440bdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "On each box in the boxplot, the left side is the 25th percentile, \nthe middle line is the 50th percentile while the right side is the 75th percentile.\nConsider reviewing the answer to Q2 if this is not sufficiently helpful.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q3\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: On each box in the boxplot, the left side is the 25th percentile, \nthe middle line is the 50th percentile while the right side is the 75th percentile.\nConsider reviewing the answer to Q2 if this is not sufficiently helpful."
     ]
    }
   ],
   "source": [
    "# test_Q3\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c551c2",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q4: Write a few sentences explaining what the code inside the `for` loop below does and why it's doing it.  \n",
    "#### Provide your written answer in the markdown cell below.\n",
    "- You can compare your answer with the example solution provided by MarkUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08324cb1",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ce3fa41",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "Difference in Medians=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "grey",
          "line": {
           "color": "black",
           "width": 1
          },
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          3.9299999999999997,
          -1.1700000000000017,
          2.960000000000001,
          2.129999999999999,
          -1.6599999999999966,
          -0.8299999999999983,
          -0.125,
          0.7299999999999969,
          -3.5749999999999993,
          1.8099999999999952,
          1.0300000000000011,
          -3.5599999999999987,
          -0.3949999999999996,
          -3.490000000000002,
          0.22499999999999787,
          -0.7499999999999964,
          -1.9299999999999997,
          -0.4700000000000024,
          -2.594999999999999,
          0.9549999999999983,
          2.5199999999999996,
          -0.7299999999999969,
          2.914999999999999,
          2.174999999999997,
          -3.5599999999999987,
          -2.6199999999999974,
          -0.740000000000002,
          -1.0449999999999982,
          -1.7449999999999974,
          4.234999999999999,
          -1.5199999999999996,
          -1.7300000000000004,
          3.8199999999999967,
          0.740000000000002,
          -0.20500000000000185,
          -3.5549999999999997,
          0.8049999999999997,
          -1.3799999999999955,
          -1.8799999999999955,
          1.389999999999997,
          -3.125,
          3.219999999999999,
          2.309999999999995,
          -2.75,
          -2.219999999999999,
          1.4600000000000009,
          -1.3099999999999987,
          1.495000000000001,
          1.269999999999996,
          0.3949999999999996,
          3.424999999999997,
          -0.0400000000000027,
          2.3999999999999986,
          -1.389999999999997,
          -1.7000000000000028,
          0.20500000000000185,
          -3.049999999999997,
          1.6449999999999996,
          3.0899999999999963,
          0.8249999999999993,
          1.5249999999999986,
          2.174999999999997,
          0.22499999999999787,
          0.4499999999999993,
          1.5899999999999999,
          -1.9999999999999964,
          -2.309999999999995,
          -1.7449999999999974,
          -1.3550000000000004,
          -0.7299999999999969,
          -0.3949999999999996,
          -0.1750000000000007,
          3,
          -0.1750000000000007,
          -0.4700000000000024,
          1.8399999999999999,
          -1.6149999999999984,
          -2.1499999999999986,
          -4.0049999999999955,
          -0.9549999999999983,
          -2.854999999999997,
          -2.6199999999999974,
          1.7449999999999974,
          1.389999999999997,
          -1.0799999999999983,
          -2.094999999999999,
          -1.7899999999999991,
          1.7899999999999991,
          0.3949999999999996,
          -1.4799999999999969,
          -3.1700000000000017,
          0.8299999999999983,
          -1.8199999999999967,
          0.20500000000000185,
          -0.7499999999999964,
          1.9299999999999997,
          1.0249999999999986,
          -0.740000000000002,
          1.370000000000001,
          -2.0049999999999955,
          2.219999999999999,
          -0.9949999999999974,
          -0.9949999999999974,
          1.0949999999999989,
          0.5800000000000018,
          1.5249999999999986,
          0.5449999999999982,
          -1.4250000000000007,
          -0.0400000000000027,
          0.4700000000000024,
          1.8199999999999967,
          -1.3749999999999964,
          -2.174999999999997,
          -1.1799999999999962,
          -2.9450000000000003,
          1.5249999999999986,
          -2.094999999999999,
          1.0850000000000009,
          1.0949999999999989,
          -1.7899999999999991,
          -2.5699999999999967,
          2.289999999999999,
          2.6950000000000003,
          2.3699999999999974,
          1.8199999999999967,
          -3.3200000000000003,
          0.8249999999999993,
          -1.7899999999999991,
          1.2299999999999969,
          -0.20500000000000185,
          0.14000000000000057,
          2.6199999999999974,
          0.384999999999998,
          2.174999999999997,
          -0.7299999999999969,
          -1.0899999999999999,
          -2.5049999999999955,
          -2.764999999999997,
          -1.7749999999999986,
          -2.014999999999997,
          -2.364999999999995,
          -0.7299999999999969,
          2.375,
          -1.389999999999997,
          1.2949999999999946,
          2.4899999999999984,
          -3.5599999999999987,
          1.259999999999998,
          -0.14000000000000057,
          0.3949999999999996,
          1.8149999999999977,
          -0.21499999999999986,
          -2.094999999999999,
          2.8200000000000003,
          -1.3099999999999987,
          -0.3949999999999996,
          1.8199999999999967,
          4.454999999999998,
          2.599999999999998,
          2.2650000000000006,
          1.6149999999999949,
          0.384999999999998,
          2.7699999999999996,
          3.424999999999997,
          2.414999999999999,
          -1.1849999999999952,
          0.3949999999999996,
          1.370000000000001,
          3.0899999999999963,
          -1,
          1.9299999999999997,
          2.014999999999997,
          1.389999999999997,
          -0.5599999999999987,
          -2.1900000000000013,
          3.905000000000001,
          1.6099999999999994,
          3.8199999999999967,
          2.1949999999999967,
          2.129999999999999,
          -2.5249999999999986,
          0.20500000000000185,
          2.599999999999998,
          -1.894999999999996,
          -0.6600000000000001,
          1.7850000000000001,
          1.4799999999999969,
          0.4700000000000024,
          -2.5349999999999966,
          -1.0449999999999982,
          0.384999999999998,
          -1.9200000000000017,
          -2.285,
          -1.7549999999999955,
          0.125,
          -3.125,
          2.599999999999998,
          -1.259999999999998,
          -1.9849999999999994,
          -0.4700000000000024,
          -2.854999999999997,
          -0.6600000000000001,
          1.4949999999999974,
          1.389999999999997,
          1.389999999999997,
          3.5549999999999997,
          -0.0400000000000027,
          2.599999999999998,
          2.035,
          1.8199999999999967,
          1.259999999999998,
          3.1599999999999966,
          -2.719999999999999,
          -2.239999999999995,
          2.7449999999999974,
          -0.0400000000000027,
          -2.789999999999999,
          -3.1449999999999996,
          -0.20500000000000185,
          0.8299999999999983,
          2.0249999999999986,
          -2.965,
          -0.384999999999998,
          1.7249999999999979,
          1.9299999999999997,
          -0.6499999999999986,
          -1,
          2.394999999999996,
          0.9549999999999983,
          1.3000000000000007,
          -1.8099999999999987,
          -2.2099999999999973,
          -2.995000000000001,
          2.5049999999999955,
          2.6199999999999974,
          3.085000000000001,
          3.4800000000000004,
          2.0450000000000017,
          2.129999999999999,
          -2.139999999999997,
          -3.384999999999998,
          2.375,
          2.5049999999999955,
          -3.3200000000000003,
          2.1499999999999986,
          2.759999999999998,
          -0.8299999999999983,
          -1.6550000000000011,
          0.4049999999999976,
          1.4749999999999979,
          3.1999999999999993,
          1.9299999999999997,
          -1.5999999999999979,
          -0.8299999999999983,
          -0.125,
          -0.740000000000002,
          0.8299999999999983,
          2.5199999999999996,
          -2.0049999999999955,
          0.8249999999999993,
          -1.7749999999999986,
          0.07000000000000028,
          -0.3949999999999996,
          -1.4449999999999967,
          -0.3949999999999996,
          -1.9450000000000003,
          -0.5599999999999987,
          -0.8249999999999993,
          -3.4750000000000014,
          -3.125,
          0.8299999999999983,
          -1.3900000000000006,
          2.014999999999997,
          2.7449999999999974,
          0.3949999999999996,
          1.3000000000000007,
          -0.6600000000000001,
          -2.639999999999997,
          0.4700000000000024,
          -2.4099999999999966,
          -1.3099999999999987,
          -2.139999999999997,
          -3.25,
          0.9949999999999974,
          0.9549999999999983,
          2.419999999999998,
          -0.0400000000000027,
          -1.3900000000000006,
          1.375,
          -0.26000000000000156,
          2.174999999999997,
          3.349999999999998,
          -3.0899999999999963,
          1.0050000000000026,
          0.740000000000002,
          -0.20500000000000185,
          0.22499999999999787,
          -0.7949999999999982,
          -0.6499999999999986,
          -2.625,
          -1.0449999999999982,
          1.1799999999999962,
          0.8299999999999983,
          2.6149999999999984,
          0.14000000000000057,
          -1.3449999999999989,
          -0.125,
          2.129999999999999,
          3.5549999999999997,
          -1.8799999999999955,
          2.6199999999999974,
          0.8299999999999983,
          2.884999999999998,
          -2.639999999999997,
          -2.5049999999999955,
          -2.5049999999999955,
          -1.9749999999999979,
          -2.7349999999999994,
          1.9299999999999997,
          0.3949999999999996,
          -1.3449999999999989,
          2.330000000000002,
          -0.20500000000000185,
          0.3949999999999996,
          -4.765000000000001,
          -0.3949999999999996,
          0.384999999999998,
          -0.4700000000000024,
          0.20500000000000185,
          -0.20500000000000185,
          -3.4350000000000023,
          -4.344999999999999,
          1.4050000000000011,
          -2.164999999999999,
          2.3699999999999974,
          -0.3450000000000024,
          -2.3649999999999984,
          0.07000000000000028,
          -0.129999999999999,
          1.389999999999997,
          3.3550000000000004,
          -0.6999999999999993,
          3.289999999999999,
          2.3699999999999974,
          -2.6950000000000003,
          3.9099999999999966,
          1.9099999999999966,
          -2.014999999999997,
          -3.0299999999999976,
          1.9349999999999987,
          1.389999999999997,
          0.740000000000002,
          -2.879999999999999,
          1.2950000000000017,
          2.594999999999999,
          -2.780000000000001,
          1.2049999999999983,
          3.7799999999999976,
          -3.424999999999997,
          -1.7300000000000004,
          -0.6499999999999986,
          3.1899999999999977,
          -1.7749999999999986,
          -1.7449999999999974,
          1.9349999999999987,
          -2.5249999999999986,
          -1.1799999999999997,
          -0.3949999999999996,
          3.3049999999999997,
          -3.289999999999999,
          0.14000000000000057,
          0.4700000000000024,
          3.3550000000000004,
          1.5849999999999973,
          -0.47499999999999787,
          -0.6600000000000001,
          3.594999999999999,
          0.8149999999999977,
          -1.4749999999999979,
          -1.7399999999999949,
          -2.094999999999999,
          -0.9800000000000004,
          1.9099999999999966,
          0.33500000000000085,
          0.4700000000000024,
          -1.5249999999999986,
          -2.7349999999999994,
          -1.8299999999999983,
          1.4050000000000011,
          -2.75,
          -2.789999999999999,
          3.025000000000002,
          -1.0700000000000003,
          2.4849999999999994,
          2.3000000000000007,
          1.2950000000000017,
          -1.7199999999999989,
          -0.384999999999998,
          0.384999999999998,
          0.3949999999999996,
          -1.879999999999999,
          -2.6199999999999974,
          -0.14000000000000057,
          -0.7299999999999969,
          -0.21499999999999986,
          2.219999999999999,
          1.7299999999999969,
          0.9350000000000023,
          1.7199999999999989,
          0.5599999999999987,
          -2.854999999999997,
          -1.3099999999999987,
          3.7749999999999986,
          -0.14000000000000057,
          -0.129999999999999,
          0.8149999999999977,
          0.7299999999999969,
          -1.0799999999999983,
          -0.7949999999999982,
          0.6499999999999986,
          0.07000000000000028,
          -0.7499999999999964,
          -3.0549999999999997,
          1.625,
          2.719999999999999,
          -1.9849999999999994,
          -1.0799999999999983,
          0.5449999999999982,
          1.9699999999999989,
          1.2950000000000017,
          1.7449999999999974,
          -0.21499999999999986,
          -2.794999999999998,
          0.8299999999999983,
          -2.139999999999997,
          -1.4799999999999969,
          -1.8249999999999957,
          -0.384999999999998,
          -2.4099999999999966,
          -1.8199999999999967,
          -3.5599999999999987,
          -0.20500000000000185,
          -2.625,
          -2.710000000000001,
          3.164999999999999,
          3.219999999999999,
          3.294999999999998,
          -0.33500000000000085,
          -0.129999999999999,
          -3.754999999999999,
          1.389999999999997,
          2.7099999999999973,
          2.3049999999999997,
          -3.129999999999999,
          -2.0749999999999957,
          -3.134999999999998,
          -1.5649999999999977,
          0.740000000000002,
          1.2299999999999969,
          0.4499999999999993,
          -2.0749999999999957,
          1.0050000000000026,
          2.8149999999999977,
          -2.9499999999999993,
          0.3949999999999996,
          -1.4799999999999969,
          -2.285,
          2.759999999999998,
          -2.4849999999999994,
          -1.7899999999999991,
          2.6199999999999974,
          0.125,
          -2.1900000000000013,
          -3.164999999999999,
          -0.6499999999999986,
          -1.3099999999999987,
          -1.4799999999999969,
          -1.4449999999999967,
          0.14000000000000057,
          0.8299999999999983,
          1.0300000000000011,
          0.4700000000000024,
          -2.905000000000001,
          2.0199999999999996,
          -3.5549999999999997,
          -0.125,
          0.9149999999999991,
          0.8299999999999983,
          -1.4449999999999967,
          -2.9349999999999987,
          3.4349999999999987,
          -0.9149999999999991,
          0.22499999999999787,
          0.9549999999999983,
          -1.0449999999999982,
          -4.34,
          -3.164999999999999,
          -2.0650000000000013,
          -1.8299999999999983,
          -2.625,
          -0.20500000000000185,
          -1.5699999999999967,
          -2.9749999999999943,
          0.9249999999999972,
          -0.0400000000000027,
          -0.6050000000000004,
          1.0949999999999989,
          1.9299999999999997,
          0.20500000000000185,
          -2.995000000000001,
          2.6199999999999974,
          -0.6499999999999986,
          0.740000000000002,
          2.6050000000000004,
          -3.0549999999999997,
          3.6899999999999977,
          1.0899999999999999,
          0.740000000000002,
          -0.1750000000000007,
          1.5249999999999986,
          -1.6749999999999972,
          -1.8299999999999983,
          0.7299999999999969,
          -0.39000000000000057,
          -0.9549999999999983,
          -0.9949999999999974,
          3.349999999999998,
          0.8249999999999993,
          3.684999999999995,
          -3.905000000000001,
          0.6600000000000001,
          -1.6499999999999986,
          -1.8099999999999987,
          0.9149999999999991,
          1.3099999999999987,
          4.229999999999997,
          2.3699999999999974,
          1.8099999999999952,
          -2.509999999999998,
          1.9349999999999987,
          -2.8999999999999986,
          0.740000000000002,
          1.615000000000002,
          2.594999999999999,
          2.6199999999999974,
          -1.8799999999999955,
          -1.7049999999999983,
          2.5749999999999957,
          0.384999999999998,
          -3.789999999999999,
          0.9549999999999983,
          2.9549999999999983,
          -1.8799999999999955,
          -0.7949999999999982,
          2.1949999999999967,
          -1.3000000000000007,
          3.0699999999999967,
          1.9549999999999983,
          3.7749999999999986,
          -4.739999999999998,
          2.285,
          -0.6499999999999986,
          -4.645000000000003,
          0.740000000000002,
          0.14000000000000057,
          -1.0899999999999999,
          -1.7399999999999984,
          1.389999999999997,
          1.7399999999999984,
          -2.014999999999997,
          -0.27500000000000213,
          -0.7949999999999982,
          -1.0050000000000026,
          2.9800000000000004,
          2.3699999999999974,
          -2.285,
          0.4499999999999993,
          3.905000000000001,
          1.4749999999999979,
          1.259999999999998,
          2.724999999999998,
          -1.0799999999999983,
          1.0949999999999989,
          -2.120000000000001,
          1.875,
          -1.0850000000000009,
          2.594999999999999,
          2.6050000000000004,
          1.8199999999999967,
          0.8299999999999983,
          1.3099999999999987,
          3.1799999999999997,
          1.4600000000000009,
          0.7299999999999969,
          2.0199999999999996,
          0.3949999999999996,
          -1.8199999999999967,
          2.6149999999999984,
          2.759999999999998,
          -2.330000000000002,
          -0.7499999999999964,
          -2.854999999999997,
          1.6400000000000006,
          0.9949999999999974,
          -0.6600000000000001,
          -1,
          -1.0899999999999999,
          -1.8299999999999983,
          2.9549999999999983,
          0.125,
          2.4849999999999994,
          -1.0949999999999989,
          -1.3000000000000007,
          0.20500000000000185,
          0.384999999999998,
          1.384999999999998,
          3.469999999999999,
          2.4899999999999984,
          -2.764999999999997,
          2.155000000000001,
          0.8149999999999977,
          -3.2950000000000017,
          -0.3949999999999996,
          0.9549999999999983,
          -1.3049999999999962,
          -1.9299999999999997,
          0.7299999999999969,
          -1.4449999999999967,
          -1.0850000000000009,
          1.8299999999999983,
          0.9149999999999991,
          -3.25,
          -3.3649999999999984,
          2.4849999999999994,
          0.9249999999999972,
          2.719999999999999,
          -1.8749999999999964,
          -4.159999999999997,
          0.3949999999999996,
          -1.8799999999999955,
          -1.8500000000000014,
          -1.0449999999999982,
          1.0449999999999982,
          -2.5699999999999967,
          1.9099999999999966,
          2.0249999999999986,
          -2.6950000000000003,
          3.1999999999999993,
          2.960000000000001,
          -2.139999999999997,
          -4.844999999999999,
          -3.094999999999999,
          -0.8200000000000003,
          -0.6499999999999986,
          -2.6950000000000003,
          0.6600000000000001,
          0.9299999999999997,
          -1.3550000000000004,
          3.0849999999999973,
          1.1799999999999997,
          2.3699999999999974,
          -2.139999999999997,
          1.4100000000000001,
          -1.7449999999999974,
          0.384999999999998,
          -1.6300000000000026,
          2.6849999999999987,
          3.8999999999999986,
          -0.0400000000000027,
          -1.7349999999999959,
          -2.014999999999997,
          -2.6799999999999997,
          -1.9349999999999987,
          -1.5649999999999977,
          0.6600000000000001,
          -0.5599999999999987,
          1.0899999999999999,
          0.8299999999999983,
          -0.0400000000000027,
          -0.4700000000000024,
          -0.4700000000000024,
          -1.7449999999999974,
          3.9499999999999993,
          0.3949999999999996,
          -0.384999999999998,
          -1.4050000000000011,
          -0.7949999999999982,
          2.0199999999999996,
          -1.9699999999999989,
          1.370000000000001,
          -1.5249999999999986,
          -2.5,
          2.754999999999999,
          -0.6499999999999986,
          -0.8299999999999983,
          -2.224999999999998,
          0.6499999999999986,
          0.740000000000002,
          1.4799999999999969,
          1.6649999999999991,
          0.22499999999999787,
          -0.0400000000000027,
          2.414999999999999,
          -1.7300000000000004,
          2.0599999999999987,
          -0.6600000000000001,
          1.6749999999999972,
          1.4749999999999979,
          0.7299999999999969,
          4.014999999999997,
          3.5549999999999997,
          -2.224999999999998,
          -1.7449999999999974,
          -2.2099999999999973,
          -0.7850000000000001,
          2.864999999999995,
          1.3900000000000006,
          1.8000000000000007,
          -2.530000000000001,
          -1.3550000000000004,
          -1.3099999999999987,
          -1.3550000000000004,
          0.740000000000002,
          -0.9949999999999974,
          -0.3949999999999996,
          2.509999999999998,
          0.740000000000002,
          1.6749999999999972,
          -0.3949999999999996,
          2.364999999999995,
          -0.7499999999999964,
          -1.5899999999999999,
          -1.5399999999999991,
          5.725000000000001,
          4.975000000000001,
          1.5899999999999999,
          -4.015000000000004,
          -2.5049999999999955,
          1.259999999999998,
          3.4800000000000004,
          -2.014999999999997,
          0.9549999999999983,
          1.4749999999999979,
          -0.5599999999999987,
          -0.9549999999999983,
          0.3949999999999996,
          -2.835000000000001,
          0.9949999999999974,
          -0.7850000000000001,
          0.740000000000002,
          -0.4700000000000024,
          2.4849999999999994,
          -0.6499999999999986,
          1.875,
          -1.3550000000000004,
          -3.7349999999999994,
          2.0599999999999987,
          2.0799999999999983,
          -1.8799999999999955,
          2.0199999999999996,
          -1.3749999999999964,
          1.9249999999999972,
          -2.139999999999997,
          -3.25,
          2.424999999999997,
          2.7349999999999994,
          3.349999999999998,
          2.8399999999999963,
          -1.384999999999998,
          2.039999999999999,
          5.225000000000001,
          -0.9149999999999991,
          -1.7300000000000004,
          -0.740000000000002,
          0.8149999999999977,
          2.285,
          -3.25,
          -1.9549999999999983,
          1.0449999999999982,
          1.4749999999999979,
          2.6199999999999974,
          -0.26000000000000156,
          2.1099999999999994,
          -3.0549999999999997,
          2.4849999999999994,
          -0.20500000000000185,
          3.085000000000001,
          -3.1499999999999986,
          -1.1400000000000006,
          0.9350000000000023,
          1.8299999999999983,
          0.740000000000002,
          -2.164999999999999,
          2.0199999999999996,
          2.594999999999999,
          -0.20500000000000185,
          1.5899999999999999,
          0.20500000000000185,
          -3.164999999999999,
          2.9549999999999983,
          0.8299999999999983,
          3.349999999999998,
          -1.6300000000000026,
          0.4049999999999976,
          2.0199999999999996,
          2.960000000000001,
          -3.9400000000000013,
          1.375,
          -2.049999999999997,
          -1.3099999999999987,
          4.014999999999997,
          -2.8999999999999986,
          1.4799999999999969,
          1.0449999999999982,
          -2.75,
          2.594999999999999,
          0.384999999999998,
          -0.740000000000002,
          -3.269999999999996,
          -2.094999999999999,
          0.6499999999999986,
          -0.0400000000000027,
          -0.384999999999998,
          0.9549999999999983,
          3.0050000000000026,
          2.8249999999999993,
          5.135000000000002,
          2.0799999999999983,
          -0.21499999999999986,
          -0.06500000000000128,
          1.4799999999999969,
          -0.8200000000000003,
          0.22499999999999787,
          -0.14000000000000057,
          -2.594999999999999,
          -0.129999999999999,
          -0.3949999999999996,
          2.014999999999997,
          -2.094999999999999,
          -4.649999999999999,
          -1.0949999999999989,
          -0.6600000000000001,
          -3.405000000000001,
          2.7749999999999986,
          -0.14000000000000057,
          -1.0050000000000026,
          -1.2899999999999991,
          -0.740000000000002,
          -1.9649999999999963,
          -2.009999999999998,
          -1.5249999999999986,
          2.3999999999999986,
          -2.5249999999999986,
          0.8249999999999993,
          -2.309999999999995,
          -2.6199999999999974,
          0.9549999999999983,
          1.3099999999999987,
          3.4800000000000004,
          -1.3000000000000007,
          -2.5249999999999986,
          -1.4449999999999967,
          3.2049999999999983,
          -0.9549999999999983,
          3.424999999999997,
          2.484999999999996,
          0.120000000000001,
          -0.0400000000000027,
          2.174999999999997,
          0.7299999999999969,
          1.259999999999998,
          -2.219999999999999,
          -0.14000000000000057,
          -0.8299999999999983,
          0.3949999999999996,
          -1.0050000000000026,
          2.104999999999997,
          1.75,
          -0.9549999999999983,
          -1.9299999999999997,
          -1.6550000000000011,
          1.0449999999999982,
          -0.0400000000000027,
          -0.129999999999999,
          -1.4250000000000007,
          -0.6499999999999986,
          -0.6600000000000001,
          2.375,
          2.129999999999999,
          -1.3099999999999987,
          -5.350000000000001,
          -0.4700000000000024,
          -1.6550000000000011,
          -5.284999999999997,
          -1.8299999999999983,
          0.8299999999999983,
          -2.424999999999997,
          -3.5749999999999993,
          -0.8299999999999983,
          0.9299999999999997,
          -0.5599999999999987,
          -2.495000000000001,
          2.0599999999999987,
          -0.8149999999999977,
          0.4700000000000024,
          -1.0949999999999989,
          -1.0949999999999989,
          -1.375,
          1.375,
          1.4549999999999983,
          0.3949999999999996,
          3.0699999999999967,
          -3.0749999999999957,
          -1.6550000000000011,
          -1.3749999999999964,
          -4.344999999999999,
          -1.4449999999999967,
          -1.3550000000000004,
          -6.024999999999999,
          3.094999999999999,
          -0.20500000000000185,
          1.4600000000000009,
          -0.7499999999999964,
          -2.4049999999999976,
          0.9549999999999983,
          2.84,
          -1.389999999999997,
          0.8249999999999993,
          -0.125,
          1.8199999999999967,
          0.7499999999999964,
          0.8249999999999993,
          0.8049999999999997,
          -3.164999999999999,
          -2.6950000000000003,
          -3.4750000000000014,
          -1.8299999999999983,
          -2.1900000000000013,
          2.599999999999998,
          -0.7499999999999964,
          0.14000000000000057,
          -1.9699999999999989,
          3.289999999999999,
          -2.009999999999998,
          -1.8799999999999955,
          1.4799999999999969,
          0.4700000000000024,
          1.9399999999999977,
          -0.6499999999999986,
          1.5899999999999999,
          2.9549999999999983,
          -1.3449999999999989,
          3.0799999999999983,
          -2.7699999999999996,
          -0.6600000000000001,
          -1.5249999999999986,
          0.3949999999999996,
          1.259999999999998,
          4.549999999999997,
          -1.0449999999999982,
          0.9949999999999974,
          -1.0050000000000026,
          0.33999999999999986,
          -2.424999999999997,
          -1.6600000000000001,
          0.8249999999999993,
          -3.0549999999999997,
          -1.0799999999999983,
          1.129999999999999,
          3.6499999999999986,
          -1.9549999999999983,
          -0.9949999999999974,
          -0.5599999999999987,
          -0.6600000000000001,
          3.0849999999999973,
          -1.5649999999999977,
          2.6549999999999976,
          -2.309999999999995,
          2.174999999999997,
          2.754999999999999,
          3.8199999999999967,
          -0.7850000000000001,
          -0.6600000000000001,
          1.5700000000000003,
          -1.7049999999999983,
          0.33500000000000085,
          -0.20500000000000185,
          -0.14000000000000057,
          -0.384999999999998,
          -0.0400000000000027,
          -2.710000000000001,
          0.33500000000000085,
          -1.3550000000000004,
          -0.7850000000000001,
          -0.14000000000000057,
          -0.6050000000000004,
          1.384999999999998,
          2.174999999999997,
          -1.4799999999999969,
          -0.26000000000000156
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "color": "red",
           "dash": "dash",
           "width": 3
          },
          "type": "line",
          "x0": -4.57,
          "x1": -4.57,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "red",
           "dash": "dash",
           "width": 3
          },
          "type": "line",
          "x0": 4.57,
          "x1": 4.57,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Difference in Medians"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.012"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_test_statistic = np.diff(anxiety_data.groupby('social_media_usage').median().values.flatten())\n",
    "\n",
    "np.random.seed(1) # make the simulation reproducible...\n",
    "repetitions = 1000 \n",
    "irrelevant_labels_null_hypothesis_simulated_values = []\n",
    "\n",
    "shuffled_anxiety_data = anxiety_data.copy() # you should essentially always use `.copy()` for data frames; otherwise,\n",
    "# changes to the new data frame will also appear in the original version of the data frame as well(!)\n",
    "\n",
    "for i in range(repetitions):\n",
    "    shuffled_anxiety_data['social_media_usage'] = anxiety_data['social_media_usage'].sample(frac=1).values\n",
    "    permutation_statistic = np.diff(shuffled_anxiety_data.groupby('social_media_usage').median().values.flatten())[0]\n",
    "    irrelevant_labels_null_hypothesis_simulated_values += [permutation_statistic]\n",
    "\n",
    "fig = px.histogram(pd.DataFrame({'Difference in Medians': irrelevant_labels_null_hypothesis_simulated_values}), \n",
    "                   x='Difference in Medians', color_discrete_sequence=['grey'])\n",
    "fig.update_traces(marker_line_width=1, marker_line_color=\"black\")\n",
    "fig.add_vline(x=observed_test_statistic[0], line_width=3, line_dash=\"dash\", line_color=\"red\")\n",
    "fig.add_vline(x=abs(observed_test_statistic[0]), line_width=3, line_dash=\"dash\", line_color=\"red\")\n",
    "fig.show()\n",
    "\n",
    "num_as_or_more_extreme = (abs(np.array(irrelevant_labels_null_hypothesis_simulated_values)) >= \n",
    "                          abs(observed_test_statistic)).sum()\n",
    "p_value = num_as_or_more_extreme / repetitions\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "075f45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\n\"\n",
    "hint += \"Included as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += \"The code overall produces a nonparametric permutation test p-value\\n\"\n",
    "hint += \"based on randomly shuffling the group labels under a (null hypothesis) assumption that they don't matter.\\n\\n\"\n",
    "hint += \"The first line of code in the `for` loop first shuffles the \\\"High\\\" and \\\"Low\\\" social media usage group labels\\n\"\n",
    "hint += \"for each observation. This implicitly assumes the outcomes for both groups are sampled from the same population\\n\"\n",
    "hint += \"(so that that actual group assignment label doesn't matter when estimating a population median from a sample),\\n\"\n",
    "hint += \"and that this population can be relatively reasonably 'represented' or 'estimated' based on the combined samples.\\n\"\n",
    "hint += \"This idea as a null hypothesis will thus be true for this simulated data (which treats the combined sample\\n\"\n",
    "hint += \"as the single population). So the subsequently calculated (median difference) statistic represents a draw from\\n\"\n",
    "hint += \"the sampling distribution of the median difference statistic under this null hypothesis assumption that it's\\n\"\n",
    "hint += \"calculated from two samples drawn from the same population (which thus have the same population median).\\n\"\n",
    "hint += \"Each repetition of the `for` loop allows us to repeatedly sample in this manner, creating the simulation\\n\"\n",
    "hint += \"of the sampling distribution of the median difference statistic under this null hypothesis assumption.\\n\\n\"\n",
    "hint += \"It's worth re-emphasizing that this is nonparametric since the two samples themselves are used to represent\\n\"\n",
    "hint += \"the population, and our analysis proceeds on the basis of that assumption. The more accurately the two\\n\"\n",
    "hint += \"samples actually represent the combined true populations, the more reliable the nonparametric analysis will be.\\n\"\n",
    "hint += \"Of course if the samples are wildly idiosyncratic and strange and thus don't well-represent their populations,\\n\"\n",
    "hint += \"then they'll make for 'unusual' statistical analysis results; but, this is true of any analysis that uses\\n\" \n",
    "hint += \"an 'unusual' sample that's just randomly 'strange' by the chance luck of the draw of the sample itself.\\n\\n\"\n",
    "hint += \"We will finally judge evidence against our null hypothesis by considering how 'strange' the observed test\\n\"\n",
    "hint += \"statistic is relative to the sampling distirbution based on assuming the 'one population' null hypothesis.\\n\"\n",
    "hint += \"If the observed test statistic doesn't seem like a reasonable possible sample from this sampling\\n\"\n",
    "hint += \"distribution (made based on assuming this null hypothesis) then the most sensible explanation would be\\n\"\n",
    "hint += \"that the assumption of the null hypothesis is likely not true!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20ee26d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nThe code overall produces a nonparametric permutation test p-value\nbased on randomly shuffling the group labels under a (null hypothesis) assumption that they don't matter.\n\nThe first line of code in the `for` loop first shuffles the \"High\" and \"Low\" social media usage group labels\nfor each observation. This implicitly assumes the outcomes for both groups are sampled from the same population\n(so that that actual group assignment label doesn't matter when estimating a population median from a sample),\nand that this population can be relatively reasonably 'represented' or 'estimated' based on the combined samples.\nThis idea as a null hypothesis will thus be true for this simulated data (which treats the combined sample\nas the single population). So the subsequently calculated (median difference) statistic represents a draw from\nthe sampling distribution of the median difference statistic under this null hypothesis assumption that it's\ncalculated from two samples drawn from the same population (which thus have the same population median).\nEach repetition of the `for` loop allows us to repeatedly sample in this manner, creating the simulation\nof the sampling distribution of the median difference statistic under this null hypothesis assumption.\n\nIt's worth re-emphasizing that this is nonparametric since the two samples themselves are used to represent\nthe population, and our analysis proceeds on the basis of that assumption. The more accurately the two\nsamples actually represent the combined true populations, the more reliable the nonparametric analysis will be.\nOf course if the samples are wildly idiosyncratic and strange and thus don't well-represent their populations,\nthen they'll make for 'unusual' statistical analysis results; but, this is true of any analysis that uses\nan 'unusual' sample that's just randomly 'strange' by the chance luck of the draw of the sample itself.\n\nWe will finally judge evidence against our null hypothesis by considering how 'strange' the observed test\nstatistic is relative to the sampling distirbution based on assuming the 'one population' null hypothesis.\nIf the observed test statistic doesn't seem like a reasonable possible sample from this sampling\ndistribution (made based on assuming this null hypothesis) then the most sensible explanation would be\nthat the assumption of the null hypothesis is likely not true!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q4\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: \n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\nThe code overall produces a nonparametric permutation test p-value\nbased on randomly shuffling the group labels under a (null hypothesis) assumption that they don't matter.\n\nThe first line of code in the `for` loop first shuffles the \"High\" and \"Low\" social media usage group labels\nfor each observation. This implicitly assumes the outcomes for both groups are sampled from the same population\n(so that that actual group assignment label doesn't matter when estimating a population median from a sample),\nand that this population can be relatively reasonably 'represented' or 'estimated' based on the combined samples.\nThis idea as a null hypothesis will thus be true for this simulated data (which treats the combined sample\nas the single population). So the subsequently calculated (median difference) statistic represents a draw from\nthe sampling distribution of the median difference statistic under this null hypothesis assumption that it's\ncalculated from two samples drawn from the same population (which thus have the same population median).\nEach repetition of the `for` loop allows us to repeatedly sample in this manner, creating the simulation\nof the sampling distribution of the median difference statistic under this null hypothesis assumption.\n\nIt's worth re-emphasizing that this is nonparametric since the two samples themselves are used to represent\nthe population, and our analysis proceeds on the basis of that assumption. The more accurately the two\nsamples actually represent the combined true populations, the more reliable the nonparametric analysis will be.\nOf course if the samples are wildly idiosyncratic and strange and thus don't well-represent their populations,\nthen they'll make for 'unusual' statistical analysis results; but, this is true of any analysis that uses\nan 'unusual' sample that's just randomly 'strange' by the chance luck of the draw of the sample itself.\n\nWe will finally judge evidence against our null hypothesis by considering how 'strange' the observed test\nstatistic is relative to the sampling distirbution based on assuming the 'one population' null hypothesis.\nIf the observed test statistic doesn't seem like a reasonable possible sample from this sampling\ndistribution (made based on assuming this null hypothesis) then the most sensible explanation would be\nthat the assumption of the null hypothesis is likely not true!"
     ]
    }
   ],
   "source": [
    "# test_Q4\n",
    "assert False, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002c359",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q5: Which statement below best states the evidence you have against the *null hypothesis* based on the simulated p-value above?\n",
    "A. `0.10 < p-value`: No evidence against the null hypothesis  \n",
    "B. `0.05 < p-value <= 0.10`: Weak evidence against the null hypothesis  \n",
    "C. `0.01 < p-value <= 0.05`: Moderate evidence against the null hypothesis  \n",
    "D. `0.001 < p-value <= 0.01`: Strong evidence against the null hypothesis  \n",
    "E. `p-value < 0.001`: Very strong evidence against the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678adfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: your answer will be tested!\n",
    "Q5 = None # Assign either 'A' or 'B' or 'C' or 'D' or 'E' to `Q5` instead of `None`\n",
    "# E.g., Q5 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da789e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"The null hypothesis assumes that there's no difference in the median anxiety \\n\"\n",
    "hint += \"level between the 'High' and 'Low' frequency social media usage populations in question.\\n\"\n",
    "hint += \"The p-value of 0.012 represents MODERATE evidence against the null hypothesis that the \\n\"\n",
    "hint += \"median anxiety level among \\\"High\\\" and \\\"Low\\\" social media usage groups is the same.\\n\\n\"\n",
    "hint += \"Further, the observed difference indicates that individuals with \\\"High\\\" social media usage\\n\"\n",
    "hint += \"have MORE anxiety than individuals with \\\"Low\\\" social media usage; however, if we reject the\\n\"\n",
    "hint += \"null hypothesis in favor of the alternative hypothesis, all that we are \\\"formally\\\" claiming \\n\"\n",
    "hint += \"is that the groups have different medians (and not necessarily which is larger...).\"\n",
    "test = Q5 == 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae89599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q5\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abcc58f",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q6: Does this data support the claim that the ***median*** anxiety level is different for those who use social media in high frequency compared to those who use social media in lower frequency?  How about the claim that \"usage of social media increases anxiety levels\"?\n",
    "\n",
    "A. Yes to the first, and yes to the second... there is a difference in median anxiety levels for those who use social media in high frequency compared to those who use social media in lower frequency, and it is because social media increases anxiety levels\n",
    "\n",
    "B. Yes to the first; but, no to the second... it seems possible -- not saying it's true, just plausible -- that different predispositions to anxiety could also have different predispositions to social media usage.  \n",
    "\n",
    "C. No to the first, and no to the second... this data does not adequately support the claim that the median anxiety level is different for those who use social media in high frequency compared to those who use social media in lower frequency  \n",
    "\n",
    "D. No to the first; but, yes to the second... the claim that the median anxiety level is different for those who use social media in high frequency compared to those who use social media in lower frequency is not supported, but we know usage of social media increases anxiety levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5363f3f8",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q6: your answer will be tested!\n",
    "Q6 = None # Assign either 'A' or 'B' or 'C' or 'D' to `Q6` instead of `None`\n",
    "# E.g., Q6 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f3410d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"Note that the first part of the question is the null hypothesis,\\n\"\n",
    "hint += \"so the data is how we may be able to provide evidence against the null hypothesis.\\n\"\n",
    "hint += \"Does the null hypothesis say anything about the cause of difference between median\\n\"\n",
    "hint += \"anxiety levels?  This is a question of of potential counfounding... that is, pre-\\n\"\n",
    "hint += \"existing differences between the two experimental groups we don't really know about...\"\n",
    "test = Q6 == 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8afa0568",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Note that the first part of the question is the null hypothesis,\nso the data is how we may be able to provide evidence against the null hypothesis.\nDoes the null hypothesis say anything about the cause of difference between median\nanxiety levels?  This is a question of of potential counfounding... that is, pre-\nexisting differences between the two experimental groups we don't really know about...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q6\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: Note that the first part of the question is the null hypothesis,\nso the data is how we may be able to provide evidence against the null hypothesis.\nDoes the null hypothesis say anything about the cause of difference between median\nanxiety levels?  This is a question of of potential counfounding... that is, pre-\nexisting differences between the two experimental groups we don't really know about..."
     ]
    }
   ],
   "source": [
    "# test_Q6\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a7066",
   "metadata": {},
   "source": [
    "### Q7: Use `scipy.stats.median_test` to calculate a p-value which could be used to provide evidence of a difference between the two social media usage groups.\n",
    "\n",
    "#### Provide your answer rounded to 3 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dabc6d",
   "metadata": {},
   "source": [
    "> - Hint 1: The \"median test\" produces a nonparametric p-value under the null hypothesis assumption that the median of two populations (here median anxiety levels of \"High\" and \"Low\" social media usage populations) are the same.\n",
    "> \n",
    "> ```python\n",
    "> from scipy import stats \n",
    "> stats.median_test(series_A, series_B)\n",
    "> # where `series_A` and `series_B` are your two samples\n",
    "> ```\n",
    "> \n",
    "> - Hint 2: Use the `numpy.round` function to round your calculation.\n",
    ">\n",
    "> - Hint 3: The \"median test\" is nonparametric just like the permutation test p-value simulate above; however, they are not quite the same test because they are based on slightly different assumptions. Notice how the null hypothesis assumptions between the two are slighly different: \n",
    ">   - Shuffling the labels assumes that the labels don't matter, which implies that there's no difference between the populations the two samples come from; which, is a very strong statement null hypothesis (and we generally might expect stronger assumptions to be helpful in producing slightly small p-values...).\n",
    ">   - The \"median test\" instead is just based on assuming if the medians of the two populations are the the same, then the null hypothesis should be that half of the observations in the first group should be larger than half of the observations in the second group, and vice-versa; which, can be used to contruct another test based on the Binomial distribution in a manner that is very much analagously to how such a Binomial test was created for a one-sample context...\n",
    ">     - Since the assumption of the \"median test\" is a little simpler and weaker than assuming two populations are identical and their samples interchangable, we'd expect p-values from a \"median test\" to be a little larger than p-values from a test based on a null hypothesis with slightly stronger assumptions...\n",
    ">     - Nonparametric p-values tend be a little bit larger than their parametric counterparts exactly because nonparametric null hypotheses tend to make fewer assumptions regarding the populations they're testing than their parametric counterparts which need to rely upon assumptions about the populations producing the samples being analyzed...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b49c9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# space for your work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90dd38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: your answer will be tested!\n",
    "Q7 = None  # Assign p-value rounded to 3 decimal places to Q7 instead of 'None'\n",
    "# E.g., Q7 = '0.987'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcdfab35",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Got None for p-value but should be 0.03",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q7\u001b[39;00m\n\u001b[0;32m      2\u001b[0m p_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(stats\u001b[39m.\u001b[39mmedian_test(anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLow\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m      3\u001b[0m                                      anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHigh\u001b[39m\u001b[39m\"\u001b[39m])[\u001b[39m1\u001b[39m], \u001b[39m3\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[39massert\u001b[39;00m Q7 \u001b[39m==\u001b[39m p_value, \u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(Q7) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m for p-value but should be \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(p_value)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Got None for p-value but should be 0.03"
     ]
    }
   ],
   "source": [
    "# test_Q7\n",
    "social_media_usage = np.repeat([\"Low\", \"High\"], [30, 16])\n",
    "anxiety_scores = [24.64, 39.29, 16.32, 32.83, 28.02, \n",
    "                   33.31, 20.60, 21.13, 26.69, 28.90,\n",
    "                   26.43, 24.23, 7.10,  32.86, 21.06,\n",
    "                   28.89, 28.71, 31.73, 30.02, 21.96,\n",
    "                   25.49, 38.81, 27.85, 30.29, 30.72,\n",
    "                   21.43, 22.24, 11.12, 30.86, 19.92,\n",
    "                   33.57, 34.09, 27.63, 31.26,\n",
    "                   35.91, 26.68, 29.49, 35.32,\n",
    "                   26.24, 32.34, 31.34, 33.53,\n",
    "                   27.62, 42.91, 30.20, 32.54]\n",
    "anxiety_data = pd.DataFrame({'anxiety_scores': anxiety_scores, 'social_media_usage': social_media_usage})\n",
    "p_value = np.round(stats.median_test(anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"Low\"], \n",
    "                                     anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"High\"])[1], 3)\n",
    "assert Q7 == p_value, \"Got \" + str(Q7) + \" for p-value but should be \" + str(p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a57f4",
   "metadata": {},
   "source": [
    "### Q8: Is the \"median test\" a parametric or non-parametric test and why?\n",
    "\n",
    "A. Parametric since the assumption that the population medians are equal implies that each population is normally distributed  \n",
    "B. Parametric since the boxplots of the data and histogram of the sampling distribution appears to be normally distributed  \n",
    "C. Nonparametric since a sample can never be normally distributed  \n",
    "D. Nonparametric since it makes no distributional assumptions (such as normality) about either of the population  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b198aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: your answer will be tested!\n",
    "Q8 = None  # Assign either 'A' or 'B' or 'C' or 'D' to `Q8` instead of `None`\n",
    "# E.g., Q8 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e2178a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"Review the hints in the previous question Q7...\"\n",
    "test = Q8 == 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b158be3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Review the hints in the previous question Q7...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q8\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: Review the hints in the previous question Q7..."
     ]
    }
   ],
   "source": [
    "# test_Q8\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede7d590",
   "metadata": {},
   "source": [
    "### Q9: Use `scipy.stats.mannwhitneyu` to calculate a p-value which could be used to provide evidence of a difference between the two social media usage groups.\n",
    "\n",
    "#### Provide your answer rounded to 3 decimal places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406d4e1",
   "metadata": {},
   "source": [
    "> - Hint 1: the \"Mann-Whitney U test\" is based on a null hypothesis that assumes there is \"no actual distributional difference between two populations\" (here \"High\" and \"Low\" social media usage populations). \n",
    "> ```python\n",
    "> stats.mannwhitneyu(series_A, series_B)\n",
    "> # where `series_A` and `series_B` are your two samples\n",
    "> # Do not use `scipy.stats.wilcoxon`... that's for \"paired\" samples \n",
    "> # with one-to-one pairing of observations...\n",
    "> ```\n",
    "> - Hint 2: The \"Mann-Whitney U test\" is based on a null hypothesis that uses a stronger assumption compared to the median test that is identical to the assumption of the permutation test used to produce the initially simulated p-value; however, there is a slight difference in the observed test statistic used by the \"Mann-Whitney U test\" compared to the observed difference of medians used in the permutation test...\n",
    ">   - Using the assumption of \"no actual distributional difference between two populations\" implies that if all observations are \"ranked\" smallest to largest, the sum of the ranks should end up the same on average. This, however, means the \"Mann-Whitney U test\" will produce its p-value based on all the data (ranks totalling equivalently) as opposed to just considering the difference between the medians in two samples.  Making a p-value based on all the relative ranks of the samples will of course be more informative than just the medians of samples; so, even though the base assumption of the \"Mann-Whitney U test\" null hypothesis is the same as the permutation test, the data is used in a more powerful manner in the \"Mann-Whitney U test\"...\n",
    "> - Hint 3: The \"Mann-Whitney U test\" is a two sample test that is (of coures) distinct from the \"Wilcoxon Rank Sum test\" (`scipy.stats.wilcoxon`). The former is for two samples where the observations don't come in pairs; whereas, the latter is for when there are two samples but the observations have a natural pairing with each other.\n",
    ">    - Our samples don't involve having measurements on twins or something like that, so the our samples don't naturally come in pairs...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee764049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for your work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a301d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9: your answer will be tested!\n",
    "Q9 = None  # Assign p-value rounded to 3 decimal places to Q9 instead of 'None'\n",
    "# E.g., Q9 = '0.987'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bca3e636",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Got None for p-value but should be 0.004",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q9\u001b[39;00m\n\u001b[0;32m      2\u001b[0m p_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(stats\u001b[39m.\u001b[39mmannwhitneyu(anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLow\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m      3\u001b[0m                                       anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHigh\u001b[39m\u001b[39m\"\u001b[39m])[\u001b[39m1\u001b[39m], \u001b[39m3\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[39massert\u001b[39;00m Q9 \u001b[39m==\u001b[39m p_value, \u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(Q9) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m for p-value but should be \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(p_value)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Got None for p-value but should be 0.004"
     ]
    }
   ],
   "source": [
    "# test_Q9\n",
    "p_value = np.round(stats.mannwhitneyu(anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"Low\"], \n",
    "                                      anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"High\"])[1], 3)\n",
    "assert Q9 == p_value, \"Got \" + str(Q9) + \" for p-value but should be \" + str(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba568ffc",
   "metadata": {},
   "source": [
    "### Q10: Is the \"Mann-Whitney U test\" a parametric or non-parametric test and why?\n",
    "\n",
    "A. Parametric since the assumption of \"no actual difference between groups\" can only occur if each population is normally distributed   \n",
    "B. Parametric since the boxplots of the data and histogram of the sampling distribution appears to be normally distributed  \n",
    "C. Nonparametric since the two populations might not be normally distributed  \n",
    "D. Nonparametric since the two populations have different distributions and so only one can be normally distributed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6d01c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10: your answer will be tested!\n",
    "Q10 = None  # Assign either 'A' or 'B' or 'C' or 'D' to `Q10` instead of `None`\n",
    "# E.g., Q10 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e51ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = 'Is there any specific distribution assumption, such as normality\\n'\n",
    "hint += 'made about the distributions of the populations under consideration?\\n\\n'\n",
    "hint += 'The hints in Q7 and Q9 should hopefully provide some good conversation\\n'\n",
    "hint += 'that will be helpful for considering the nature of nonparameteric tests...'\n",
    "test = Q10 == 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5598ee44",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Is there any specific distribution assumption, such as normality\nmade about the distributions of the populations under consideration?\n\nThe hints in Q7 and Q9 should hopefully provide some good conversation\nthat will be helpful for considering the nature of nonparameteric tests...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q10\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: Is there any specific distribution assumption, such as normality\nmade about the distributions of the populations under consideration?\n\nThe hints in Q7 and Q9 should hopefully provide some good conversation\nthat will be helpful for considering the nature of nonparameteric tests..."
     ]
    }
   ],
   "source": [
    "# test_Q10\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8cbd1a",
   "metadata": {},
   "source": [
    "### Q11: Use `scipy.stats.ttest_ind` to calculate a p-value which could be used to provide evidence of a difference between the two social media usage groups.\n",
    "\n",
    "#### Provide your answer rounded to 3 decimal places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f6fee",
   "metadata": {},
   "source": [
    "> - Hint 1: The \"two-sample t-test\" has a null hypothesis that assumes the means of two populations (here mean anxiety levels of \"High\" and \"Low\" social media usage populations) are equal and that the samples are drawn from normally distributed populations.\n",
    "> ```python\n",
    "> stats.ttest_ind(series_A, series_B, equal_var=False)\n",
    "> # where `series_A` and `series_B` are your two samples\n",
    "> # Do not use `stats.ttest_rel`... that's for \"paired\" samples \n",
    "> # with one-to-one pairing of observations...\n",
    "> ```\n",
    "> - Hint 2: a mean is of course distinct from a median, generally speaking; however, the mean and median are the same for a population that is symmetric such as a normally distributed population; thus, the assumption of the null hypothesis that the distributions are normally disributed and have the same means here implies that they have the same medians...\n",
    "> - Hint 3: when doing a twosample t-test it is possible to make assumptions about the two normal populations under examination, such as if the variances (or equivalently the standard deviations) of the two populations are the same or not. By default `stats.ttest_ind` uses `equal_var=True`; but, given the observed boxplots of these two distributions, it seems like `equal_var=False` is a better assumption for this test; so, that's what you should use here as in the example code above...\n",
    "> - Hint 4: there is another function `stats.ttest_rel` which is (of course) distinct from `stats.ttest_ind`. The difference between these is analagous to the difference between the \"Wilcoxon Rank Sum test\" (`scipy.stats.wilcoxon`) and the \"Mann-Whitney U test\" (`scipy.stats.mannwhitneyu`); namely, the former is for when the observations have a natural pairing with each other, while the latter is when the observations don't come in pairs.\n",
    ">    - Our samples don't involve having measurements on twins or something like that, so the our samples don't naturally come in pairs...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fcec329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for your work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "140593d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11: your answer will be tested!\n",
    "Q11 = None  # Assign p-value rounded to 3 decimal places to Q11 instead of 'None'\n",
    "# E.g., Q11 = '0.987'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddf35d83",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Got None for p-value but should be 0.001",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q11\u001b[39;00m\n\u001b[0;32m      2\u001b[0m p_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(stats\u001b[39m.\u001b[39mttest_ind(anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLow\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m      3\u001b[0m                                    anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHigh\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m      4\u001b[0m                                    equal_var\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m1\u001b[39m], \u001b[39m3\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[39massert\u001b[39;00m Q11 \u001b[39m==\u001b[39m p_value, \u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(Q11) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m for p-value but should be \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(p_value)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Got None for p-value but should be 0.001"
     ]
    }
   ],
   "source": [
    "# test_Q11\n",
    "p_value = np.round(stats.ttest_ind(anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"Low\"], \n",
    "                                   anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"High\"], \n",
    "                                   equal_var=False)[1], 3)\n",
    "assert Q11 == p_value, \"Got \" + str(Q11) + \" for p-value but should be \" + str(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d699173e",
   "metadata": {},
   "source": [
    "### Q12: Is the \"two-sample t-test\" a parametric or non-parametric test and why?\n",
    "\n",
    "A. Parametric since we assume samples are drawn from normally distributed populations  \n",
    "B. Parametric since the boxplots of the data and histogram of the sampling distribution appears to be normally distributed  \n",
    "C. Nonparametric since the assumption that the means for each group being equal does not imply that the populations are normally distributed  \n",
    "D. Nonparametric since a sample can never be normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dad64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q12: your answer will be tested!\n",
    "Q12 = None  # Assign either 'A' or 'B' or 'C' or 'D' to `Q12` instead of `None`\n",
    "# E.g., Q12 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d677814",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = 'The hints and conversation in Q7 and Q9 relative to those in Q11 should be helpful here...'\n",
    "test = Q12 == 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "149223f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The hints and conversation in Q7 and Q9 relative to those in Q11 should be helpful here...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q12\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: The hints and conversation in Q7 and Q9 relative to those in Q11 should be helpful here..."
     ]
    }
   ],
   "source": [
    "# test_Q12\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ac2ac",
   "metadata": {},
   "source": [
    "### Q13: Give the strength of evidence against the null hypothesis for the three tests considered above.\n",
    "\n",
    "1. \"Median test\" which specifies a null hypothesis that assumes the medians of the two populations are equal\n",
    "2. \"Mann-Whitney U test\" which specifies a null hypothesis that assumes the two populations are identical\n",
    "3. \"Two-sample t-test\" which specifies a null hypothesis that assumes the two populations are normally distributed with the same means<br>(but different standard deviations, for the specification above)\n",
    "\n",
    "A. `0.10 < p-value`: No evidence against the null hypothesis  \n",
    "B. `0.05 < p-value <= 0.10`: Weak evidence against the null hypothesis  \n",
    "C. `0.01 < p-value <= 0.05`: Moderate evidence against the null hypothesis  \n",
    "D. `0.001 <= p-value <= 0.01`: Strong evidence against the null hypothesis  \n",
    "E. `p-value < 0.001`: Very strong evidence against the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "161f5275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13: your answer will be tested!\n",
    "Q13 = (None,None,None) # Assign a triple tuple comprised of 'A's, 'B's, 'C's, 'D's and/or 'E' to `Q13`\n",
    "# instead of the `None` triple tuple `(None,None,None)` in the order of Median test, Mann-Whitney U test\n",
    "# and Two-sample t-test\n",
    "# E.g., Q13 = ('A','B','C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72fa649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = 'The p-values for the three tests were 0.03, 0.004, and 0.001, respectively...'\n",
    "test = Q13 == ('C', 'D', 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a9e48c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The p-values for the three tests were 0.03, 0.004, and 0.001, respectively...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q13\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: The p-values for the three tests were 0.03, 0.004, and 0.001, respectively..."
     ]
    }
   ],
   "source": [
    "# test_Q13\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86716ca6",
   "metadata": {},
   "source": [
    "### Q14: Relative to the p-value calculations based on `scipy.stats.ttest_1samp` and `scipy.stats.binom` from the homework exercise of the previous week. Which of the following is correct?\n",
    "\n",
    "A. The `stats.ttest_1samp` and `stats.binom` methods **theoretically** derive p-value under their null hypothesis, while `stats.median_test`, `stats.mannwhitneyu`, and `stats.ttest_ind` do not  \n",
    "\n",
    "B. The `stats.ttest_1samp` and `stats.ttest_ind` methods use continuous approximations of the theoretical binomial sampling distribution of the `stats.binom` and `stats.median_test` and `stats.mannwhitneyu` methods, respectively, which is why these t-tests produce nonparametric p-values  \n",
    "\n",
    "C. The `stats.ttest_1samp`, `stats.ttest_ind`, and `stats.ttest_rel` are parametric due to their assumption regarding the normally distributed nature of the populations they consider; whereas, `stats.binom`, `stats.median_test`, `stats.mannwhitneyu`, and `stats.wilcoxon` based methods are nonparametric since they rely on no specific distributional assumptions such as population normality. \n",
    "\n",
    "D. The `stats.ttest_1samp` and `stats.binom` most closely related to `stats.ttest_ind` (rather than `stats.ttest_rel`) and `stats.mannwhitneyu` and `stats.wilcoxon` (rather than `stats.median_test`), respectively.  \n",
    "\n",
    "E. `stats.ttest_1samp` and `stats.binom` are only good for 50/50 chance problems; so, `stats.median_test`, `stats.mannwhitneyu`, and `stats.ttest_ind` exist in order to consider different comparision populations.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2c22e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05688793364098088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=2.0310096011589898, pvalue=0.04493472521263044, df=99)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hint 1:\n",
    "print((1-stats.binom(n=100, p=0.5).cdf(60-1))*2)\n",
    "# Probability of getting a combination more as or extreme than 60 heads in 100 coin flips for a 50-50 coin\n",
    "\n",
    "# Hint 2:\n",
    "coin_flips = [1] * 60 + [0] * 40  # 1 for head, 0 for tails\n",
    "stats.ttest_1samp(coin_flips, 0.5) \n",
    "# Probability of getting a combination as or more extreme than 60 heads in 100 coin flips for a 50-50 coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "250b3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14: your answer will be tested!\n",
    "Q14 = None  # Assign either 'A', 'B', 'C', 'D', or 'E' to `Q14` instead of `None`\n",
    "# E.g., Q14 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6a25dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"A is wrong because all of these methods are based on theoretical derivations...\\n\"\n",
    "hint += \"A careful reading of B should suggest why it is wrong...\\n\"\n",
    "hint += \"D has it backward... in fact...\\n\"\n",
    "hint += \"`stats.median_test` has an equivalent version as a 50/50 `stats.binom` specification; and\\n\"\n",
    "hint += \"similarly, `stats.ttest_rel` ends up being a wrapper function for a specific use of `stats.ttest_1samp`.\\n\"\n",
    "hint += \"It's not quite expected that this is obvious or you should know this; but,\\n\"\n",
    "hint += \"you should be able to arrive at the correct answer by a process of elimination...\\n\"\n",
    "hint += \"Do you see why E makes an overly strict claim on the null hypotheses these methods consider?\"\n",
    "\n",
    "test = Q14 == 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17f0a666",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "A is wrong because all of these methods are based on theoretical derivations...\nA careful reading of B should suggest why it is wrong...\nD has it backward... in fact...\n`stats.median_test` has an equivalent version as a 50/50 `stats.binom` specification; and\nsimilarly, `stats.ttest_rel` ends up being a wrapper function for a specific use of `stats.ttest_1samp`.\nIt's not quite expected that this is obvious or you should know this; but,\nyou should be able to arrive at the correct answer by a process of elimination...\nDo you see why E makes an overly strict claim on the null hypotheses these methods consider?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q14\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m test, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: A is wrong because all of these methods are based on theoretical derivations...\nA careful reading of B should suggest why it is wrong...\nD has it backward... in fact...\n`stats.median_test` has an equivalent version as a 50/50 `stats.binom` specification; and\nsimilarly, `stats.ttest_rel` ends up being a wrapper function for a specific use of `stats.ttest_1samp`.\nIt's not quite expected that this is obvious or you should know this; but,\nyou should be able to arrive at the correct answer by a process of elimination...\nDo you see why E makes an overly strict claim on the null hypotheses these methods consider?"
     ]
    }
   ],
   "source": [
    "# test_Q14\n",
    "assert test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7a873",
   "metadata": {},
   "source": [
    "### Q15: Create a 90% bootstrap confidence interval estimating the difference in median anxiety scores between the social media usage groups. \n",
    "\n",
    "#### Provide your interval endpoint answers rounded to 3 decimal places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72513439",
   "metadata": {},
   "source": [
    "> - Hint 1: The process within the `for` loop in `Q4` is not quite right since it's based on the assumption of a null hypothesis that the labels don't matter; however, when making a confidence interval we do think the labels matter! So, the `for` loop for a confidence interval should instead provide a simulation producing repeated pairs of bootstrap samples which can then be used to create simulated median difference test statistic that are samples from the bootrapped sampling distribution of the difference in medians...  \n",
    "> - Hint 2: Don't forget about the `np.quantile()` function...\n",
    "> - Hint 3: Be careful that you haven't accidentally overwritten the values in `anxiety_data.anxiety_scores`...\n",
    ">   - Working instead with something like `simdata = anxiety_data.copy()` and `bootstrapped_anxiety_scores = anxiety_data.anxiety_scores.values.copy()` would help protect against this... and you can tell pretty quickly that you might be making this mistake if your simulated median difference statistics are all the same value!\n",
    "> - Hint 4: code like the following\n",
    ">   ```python\n",
    ">   simdata['anxiety_scores'][anxiety_data.social_media_usage==\"Low\"] = \\\n",
    ">      anxiety_data['anxiety_scores'][anxiety_data.social_media_usage==\"Low\"].\\\n",
    ">        sample(frac=1, replace=True).values\n",
    ">   ```\n",
    ">   will produce a\n",
    ">\n",
    ">   `SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame`  \n",
    ">\n",
    ">   because `simdata['anxiety_scores'][anxiety_data.social_media_usage==\"Low\"]` is itself a \"slice\" of a `pd.DataFrame` even if `simdata = anxiety_data.copy()`; so, instead, sequentially assign into something like \n",
    ">   - `bootstrapped_anxiety_scores = anxiety_data.anxiety_scores.values.copy()` \n",
    ">     - `bootstrapped_anxiety_scores[anxiety_data.social_media_usage==\"Low\"] = ...`\n",
    ">     - `bootstrapped_anxiety_scores[anxiety_data.social_media_usage==\"High\"] = ...`\n",
    ">   - and finally `simdata['anxiety_scores'] = bootstrapped_anxiety_scores` without any \"slice\" usage in order to use \n",
    ">   - `np.diff(simdata.groupby('social_media_usage').median().values.flatten())[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4057fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for scratch work if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "198c5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the following line at the top! And, replace `None` below with the three digit integer \n",
    "np.random.seed(None) # made from the 1st, 3rd, and 5th digits or your student number. \n",
    "\n",
    "# Code your bootstrap sampling distribution simulation here... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f10fa7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_digit_random_nubmer_seed = None \n",
    "# Match the integer created from the 1st, 3rd, and 5th digits of your student number used above...\n",
    "# your results must be based on this random number seed so that they can be confirmed during autotesting\n",
    "number_of_bootstrap_sample_repititions = None # number of simulated median difference test statistics\n",
    "# sampled from the bootstrapped sampling distribution of the difference in medians\n",
    "the_90percent_confidence_interval = (None, None) # Assign your 90% confidence interval lower and upper bounds\n",
    "# Round to 3 digits of accuracy\n",
    "Q15 = (three_digit_random_nubmer_seed, number_of_bootstrap_sample_repititions, the_90percent_confidence_interval)\n",
    "# E.g. `Q15 = (123, 10000, (0.123, 0.456))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b4c39a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m# changes to the new data frame will also appear in the original version of the data frame as well(!)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m bootstrapped_anxiety_scores \u001b[39m=\u001b[39m anxiety_data\u001b[39m.\u001b[39manxiety_scores\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(num_samples):\n\u001b[0;32m     14\u001b[0m     bootstrapped_anxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLow\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[0;32m     15\u001b[0m     anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLow\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     17\u001b[0m     bootstrapped_anxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHigh\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[0;32m     18\u001b[0m     anxiety_data\u001b[39m.\u001b[39manxiety_scores[anxiety_data\u001b[39m.\u001b[39msocial_media_usage\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHigh\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mvalues\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# test_Q15\n",
    "#Q15 = (123, 10000, (0.123, 0.456)) \n",
    "seed, num_samples, interval = Q15\n",
    "\n",
    "np.random.seed(seed) # make the simulation reproducible...\n",
    "simulated_values = []\n",
    "\n",
    "simdata = anxiety_data.copy() # you should essentially always use `.copy()` for data frames; otherwise,\n",
    "# changes to the new data frame will also appear in the original version of the data frame as well(!)\n",
    "bootstrapped_anxiety_scores = anxiety_data.anxiety_scores.values.copy()\n",
    "\n",
    "for i in range(num_samples):\n",
    "    \n",
    "    bootstrapped_anxiety_scores[anxiety_data.social_media_usage==\"Low\"] = \\\n",
    "    anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"Low\"].sample(frac=1, replace=True).values\n",
    "    \n",
    "    bootstrapped_anxiety_scores[anxiety_data.social_media_usage==\"High\"] = \\\n",
    "    anxiety_data.anxiety_scores[anxiety_data.social_media_usage==\"High\"].sample(frac=1, replace=True).values\n",
    "    \n",
    "    simdata['anxiety_scores'] = bootstrapped_anxiety_scores\n",
    "    \n",
    "    simvalue = np.diff(simdata.groupby('social_media_usage').median().values.flatten())[0]\n",
    "    simulated_values += [simvalue]\n",
    "\n",
    "calc_interval = tuple(np.round(np.quantile(simulated_values,(0.05, .95)), 3))\n",
    "assert calc_interval == interval, \"You got \" + str(interval) + \" for your 90% confidence interval but should be \" + str(calc_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a870f5",
   "metadata": {
    "deletable": false
   },
   "source": [
    "## Airbags\n",
    "The table below is adapted from a \"Biostatistics for the Biological and Health Sciences\" textbook example and presents data from a random sample of passengers sitting in the front seat of cars involved in car crashes. Based on this data we'd like to make a determination as to whether or not death rates differ for passengers in cars with airbags and passengers in cars without airbags.\n",
    "\n",
    "|                           | Airbag available | No airbag available |\n",
    "|---------------------------|------------------|---------------------|                           \n",
    "| Passenger Fatalities      |  45              | 62                  |\n",
    "| Total number of Passengers|  10,541          | 9,867               |\n",
    "\n",
    "- The code below creates a pandas data frame for this problem with the help of the `numpy.repeat` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7c2b718",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "crash_data = pd.DataFrame({'group': np.repeat([\"airbag\", \"no_airbag\"], [10541, 9867]), \n",
    "                           'outcome': np.repeat([\"dead\", \"alive\", \"dead\", \"alive\"], [45, 10541-45, 62, 9867-62])})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50ade0",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q16: In simple terms, state the claim of the *null hypothesis* for the context above that we are naturally trying to provide evidence against.  State this formally in terms of the two population parameters probabilities of death $p_{airbag}$ and $p_{no-airbag}$ in question. Finally, formally state the *alternative hypothesis* $H_1$ that makes this a *one-sided hypothesis test* such that (during the p-value calculation process) \"as or more extreme\" only considers evidence indicating that survival rates are strictly better in cars with airbags. \n",
    "\n",
    "> - Hint 1: Formulate the null and alternative hypotheses in the request 'one-sided' manner (as opposed to as a 'two-sided' specification) by using using a less than $<$ sign as opposed to the typical \"$H_1: H_0\\text{ is false}$\".  Doing so indicates that there is no evidence against the null hypothesis if the survival rates are worse for cars with airbags; but, on the other hand, this actually tends to reduce p-values by a factor of two since it means only check \"as or more extreme\" on one side (\"better than\" direction only) of the sampling distribution implied by the null hypothesis.\n",
    "> \n",
    "> - Hint 2: In the previous \"Social Media and Anxiety\" example it was suggested that it might be plausible for there to be a pre-existing association between anxiety and the choice to use social media more frequently. In this case, does it feel similarly possible that people who are more likely to die in a car crash (for whatever reason) would also be people who would choose to drive a car without an airbag? It feels like an argument of some kind of \"confounding\" affecting things here might be less likely than anxious people using more social media; but, what kind of story could you tell which might in fact produce \"confounding\" in the current car crash surival context? \n",
    "\n",
    "#### Provide your written answer in the markdown cell below.\n",
    "- The TA will manually review and confirm the correctness of your submitted answer for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3418eb",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7159b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\n\"\n",
    "hint += \"Included as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += '''\n",
    "The natural null hypothesis that we'd look to provide evidence against in this context  \n",
    "is that the chance of death in a car crash for cars with and without airbags,  \n",
    "$p_{airbag}$ and $p_{no-airbag}$, respectively, is the same. \n",
    "\n",
    "The formal null and alternative hypothesis specifications for a one-sided hypothesis test\n",
    "here would thus be\n",
    "\n",
    "$$H_0: p_{airbag} = p_{no-airbag} \\\\quad H_A:p_{airbag} < p_{no-airbag}$$\n",
    "\n",
    "which means we can provide evidence against the null hypothesis if our observed difference\n",
    "test statistic $\\\\hat p_{no-airbag} - \\\\hat p_{airbag}$ is positive; and, when computing\n",
    "p-values \"as or more extreme\" will only consider test statistics sampled under the assumption\n",
    "of the null hypothesis which are at least as large as the observed test statistic. \n",
    "\n",
    "Generally, one-sided hypothesis tests lead to smaller p-values since only half of the \n",
    "outcomes that would usually be considered \"as or more extreme\" are now counted as being so.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cae4b538",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\n\nThe natural null hypothesis that we'd look to provide evidence against in this context  \nis that the chance of death in a car crash for cars with and without airbags,  \n$p_{airbag}$ and $p_{no-airbag}$, respectively, is the same. \n\nThe formal null and alternative hypothesis specifications for a one-sided hypothesis test\nhere would thus be\n\n$$H_0: p_{airbag} = p_{no-airbag} \\quad H_A:p_{airbag} < p_{no-airbag}$$\n\nwhich means we can provide evidence against the null hypothesis if our observed difference\ntest statistic $\\hat p_{no-airbag} - \\hat p_{airbag}$ is positive; and, when computing\np-values \"as or more extreme\" will only consider test statistics sampled under the assumption\nof the null hypothesis which are at least as large as the observed test statistic. \n\nGenerally, one-sided hypothesis tests lead to smaller p-values since only half of the \noutcomes that would usually be considered \"as or more extreme\" are now counted as being so.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q16\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, hint\n",
      "\u001b[1;31mAssertionError\u001b[0m: \n\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\nIncluded as an example answer for feedback purposes only\n\n\nThe natural null hypothesis that we'd look to provide evidence against in this context  \nis that the chance of death in a car crash for cars with and without airbags,  \n$p_{airbag}$ and $p_{no-airbag}$, respectively, is the same. \n\nThe formal null and alternative hypothesis specifications for a one-sided hypothesis test\nhere would thus be\n\n$$H_0: p_{airbag} = p_{no-airbag} \\quad H_A:p_{airbag} < p_{no-airbag}$$\n\nwhich means we can provide evidence against the null hypothesis if our observed difference\ntest statistic $\\hat p_{no-airbag} - \\hat p_{airbag}$ is positive; and, when computing\np-values \"as or more extreme\" will only consider test statistics sampled under the assumption\nof the null hypothesis which are at least as large as the observed test statistic. \n\nGenerally, one-sided hypothesis tests lead to smaller p-values since only half of the \noutcomes that would usually be considered \"as or more extreme\" are now counted as being so.\n"
     ]
    }
   ],
   "source": [
    "# test_Q16\n",
    "assert False, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0741b",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q17: Use \"label shuffling\" to simulate and visualize the sampling distribution of the test statistic of the difference between $\\hat p_{no-airbag}$ and $\\hat p_{airbag}$ under the assumption that the *null hypothesis* stated in the previous question is true; and, then compute a \"permutation test\" p-value of the observed test statistic relative to this simulated sampling distribution and indicate the strength of evidence provided against the null hypothesis based on this p-value.\n",
    "\n",
    "A. `0.10 < p-value`: No evidence against the null hypothesis  \n",
    "B. `0.05 < p-value <= 0.10`: Weak evidence against the null hypothesis  \n",
    "C. `0.01 < p-value <= 0.05`: Moderate evidence against the null hypothesis  \n",
    "D. `0.001 < p-value <= 0.01`: Strong evidence against the null hypothesis  \n",
    "E. `p-value <= 0.001`: Very strong evidence against the null hypothesis\n",
    "\n",
    "> - Hint 1: The assumption that the *null hypothesis* stated in the previous question is true implies that the two samples must come from identical populations (with identical survivial proportions); thus, a permutation test p-value similar to the one computed in Q4 is an appropriate nonparametric p-value for this context. \n",
    "> - Hint 2: of course we could also choose to use the alternative methods form computing p-values that we've encountered above; but, for this question please create a \"permutation test\" p-value in order to practice this kind of simulation test. \n",
    "> - Hint 3: you could consider using something like `data.replace({'dead': 1, 'alive': 0})` to replace 'dead' and 'alive' outcomes with 1's and 0's, which might simplify working with proportions slightly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f21b34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space for scratch work if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74111033",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Keep the following line at the top! And, replace `None` below with the three digit integer \n",
    "np.random.seed(None) # made from the 1st, 3rd, and 5th digits or your student number. \n",
    "\n",
    "# Code your permutation test simulation here... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9dff4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_digit_random_nubmer_seed = None\n",
    "# Match the integer created from the 1st, 3rd, and 5th digits of your student number used above...\n",
    "# your results must be based on this random number seed so that they can be confirmed during autotesting\n",
    "number_of_bootstrap_sample_repititions = None # number of simulated difference test statistics\n",
    "# drawn from the sampling distribution of the null hypothesis used to calculate your p-value\n",
    "permutation_p_value = None # Assign to p_value your calculated p-value rounded to 3 decimal places\n",
    "# Round to 3 digits of accuracy\n",
    "strength_of_evidence_against_H0 = None # Assign either 'A' or 'B' or 'C' or 'D' or 'E' instead of `None`\n",
    "# E.g., strength_of_evidence_against_H0 = 'A'\n",
    "\n",
    "Q17 = (three_digit_random_nubmer_seed, number_of_bootstrap_sample_repititions, \n",
    "       permutation_p_value, strength_of_evidence_against_H0)\n",
    "# E.g. `Q17 = (123, 10000, 0.123, 'A')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "156e022e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# Stores test statistics simulated from the sampling distribution under H0\u001b[39;00m\n\u001b[0;32m     13\u001b[0m simulated_test_statistics_under_H0 \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(num_reps):   \n\u001b[0;32m     16\u001b[0m     \u001b[39m# shuffle group labels under null hypothesis assumption\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     simdata[\u001b[39m'\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_ones_and_zeros[\u001b[39m'\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mvalues  \n\u001b[0;32m     18\u001b[0m     \u001b[39m# simulated test statistic\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# test_Q17\n",
    "#Q17 = (123, 10000, 0.123, 'A')\n",
    "seed, num_reps, p_value, evidence = Q17\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Replace \"dead\" outcome with 1 and \"alive\" with 0 so `.mean()` gives proportion died\n",
    "# The `crash_data` Data Frame is not changed: the altered version is stored in `data_ones_and_zeros`\n",
    "data_ones_and_zeros = crash_data.replace({'dead': 1, 'alive': 0})   \n",
    "observed_test_statistic = np.diff(data_ones_and_zeros.groupby('group')['outcome'].mean())  \n",
    "simdata = data_ones_and_zeros.copy() # for shuffling to create permuation test\n",
    "\n",
    "# Stores test statistics simulated from the sampling distribution under H0\n",
    "simulated_test_statistics_under_H0 = []\n",
    "\n",
    "for i in range(num_reps):   \n",
    "    # shuffle group labels under null hypothesis assumption\n",
    "    simdata['group'] = data_ones_and_zeros['group'].sample(frac=1).values  \n",
    "    # simulated test statistic\n",
    "    simulated_test_statistic_under_H0 = np.diff(simdata.groupby('group')['outcome'].mean())\n",
    "    simulated_test_statistics_under_H0 += [simulated_test_statistic_under_H0]\n",
    "\n",
    "# Calculate p-value: no abs function as this is a one-sided test!\n",
    "num_more_extreme = (simulated_test_statistics_under_H0 >= observed_test_statistic).sum() \n",
    "calc_p_value = np.round(num_more_extreme / num_reps, 3)\n",
    "\n",
    "if calc_p_value > 0.10:\n",
    "    evidence_test = evidence == 'A'\n",
    "    actually_correct_evidence_choice = 'A'\n",
    "elif 0.05 < calc_p_value <= 0.10:\n",
    "    evidence_test = evidence == 'B'\n",
    "    actually_correct_evidence_choice = 'B'\n",
    "elif 0.01 < calc_p_value <= 0.05:\n",
    "    evidence_test = evidence == 'C'\n",
    "    actually_correct_evidence_choice = 'C'\n",
    "elif 0.001 < calc_p_value <= 0.01:\n",
    "    evidence_test = evidence == 'D'\n",
    "    actually_correct_evidence_choice = 'D'\n",
    "else:\n",
    "    evidence_test = evidence == 'E'\n",
    "    actually_correct_evidence_choice = 'E'\n",
    "\n",
    "evidence_choice_in_words = {'A': 'NO', 'B': 'WEAK', 'C': 'MODERATE', 'D': 'STRONG', 'E': 'VERY STRONG'}\n",
    "\n",
    "hint = \"You got \" + str(p_value) + \" for calculated p-value and it should be \" + str(calc_p_value) + \".\\n\"\n",
    "hint += \"You stated your p_value represents \" + evidence_choice_in_words[evidence] + \" evidence against the \\n\"\n",
    "hint += \"null hypothesis and it should represent \" + evidence_choice_in_words[actually_correct_evidence_choice]\n",
    "hint += \" evidence against the null hypothesis.\\n\\n\"\n",
    "\n",
    "hint += \"The null hypothesis assumes that there's no difference in the probability \\n\"\n",
    "hint += \"of death between the 'airbag' and 'no-airbag' populations in question.\\n\"\n",
    "hint += \"A p-value of \" + str(calc_p_value) + \" represents \" + evidence_choice_in_words[actually_correct_evidence_choice] \n",
    "hint += \" evidence against the null hypothesis.\\n\"\n",
    "hint += \"that the probability of death between the 'airbag' and 'no-airbag' groups is the same.\\n\\n\"\n",
    "hint += \"If the evidence is quite good, a one-sided hypothesis test would likely choose to reject\\n\"\n",
    "hint += \"the null hypothesis in favor of the alternative hypothesis and we might thus choose to\\n\"\n",
    "hint += \"believe that cars without airbags are MORE likely to result in death than cars with airbags.\"\n",
    "\n",
    "assert (calc_p_value == p_value) and evidence_test, hint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6da9829",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q18: Create a 95% bootstrap confidence interval estimating the difference in probability of death ($p_{airbag}$ and $p_{no-airbag})$ between passengers in cars with airbags and passengers in cars without airbags. Then visualize the distribution of the bootstrapped sample proportion differences.\n",
    "\n",
    "#### Provide your interval endpoint answers rounded to 5 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56c836d7",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# space for scratch work if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a4c5404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the following line at the top! And, replace `None` below with the three digit integer \n",
    "np.random.seed(None) # made from the 1st, 3rd, and 5th digits or your student number. \n",
    "\n",
    "# Code your bootstrap sampling distribution simulation here... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "912f9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of the bootstrapped sample proportion differences here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3222d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_digit_random_nubmer_seed = None\n",
    "# Match the integer created from the 1st, 3rd, and 5th digits of your student number used above...\n",
    "# your results must be based on this random number seed so that they can be confirmed during autotesting\n",
    "number_of_bootstrap_sample_repititions = None # number of simulated proportion difference test statistics\n",
    "# sampled from the bootstrapped sampling distribution of the difference in death proportions\n",
    "the_95percent_confidence_interval = (None, None) # Assign your 95% confidence interval lower and upper bounds\n",
    "# Round to 5 digits of accuracy\n",
    "Q18 = (three_digit_random_nubmer_seed, number_of_bootstrap_sample_repititions, the_95percent_confidence_interval)\n",
    "# E.g. `Q18 = (123, 10000, (0.12345, 0.45678))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0190c5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m bootstrapped_death_prob \u001b[39m=\u001b[39m data_ones_and_zeros\u001b[39m.\u001b[39moutcome\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     12\u001b[0m \u001b[39m# once again, we do not want to alter the `data_ones_and_zeros` DataFrame\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(num_samples):\n\u001b[0;32m     16\u001b[0m     bootstrapped_death_prob[data_ones_and_zeros\u001b[39m.\u001b[39mgroup\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mairbag\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[0;32m     17\u001b[0m     data_ones_and_zeros\u001b[39m.\u001b[39moutcome[data_ones_and_zeros\u001b[39m.\u001b[39mgroup\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mairbag\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     19\u001b[0m     bootstrapped_death_prob[data_ones_and_zeros\u001b[39m.\u001b[39mgroup\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_airbag\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[0;32m     20\u001b[0m     data_ones_and_zeros\u001b[39m.\u001b[39moutcome[data_ones_and_zeros\u001b[39m.\u001b[39mgroup\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_airbag\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msample(frac\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mvalues\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# test_Q18\n",
    "# bootstrap sampling distribution simulation\n",
    "seed, num_samples, interval = Q18\n",
    "\n",
    "np.random.seed(seed)\n",
    "simulated_values = []\n",
    "\n",
    "simdata = data_ones_and_zeros.copy()\n",
    "# may be easier for you to work with 1's and 0's to simplify our propotions\n",
    "\n",
    "bootstrapped_death_prob = data_ones_and_zeros.outcome.values.copy()\n",
    "# once again, we do not want to alter the `data_ones_and_zeros` DataFrame\n",
    "\n",
    "for i in range(num_samples):\n",
    "\n",
    "    bootstrapped_death_prob[data_ones_and_zeros.group==\"airbag\"] = \\\n",
    "    data_ones_and_zeros.outcome[data_ones_and_zeros.group==\"airbag\"].sample(frac=1, replace=True).values\n",
    "\n",
    "    bootstrapped_death_prob[data_ones_and_zeros.group==\"no_airbag\"] = \\\n",
    "    data_ones_and_zeros.outcome[data_ones_and_zeros.group==\"no_airbag\"].sample(frac=1, replace=True).values\n",
    "\n",
    "    simdata['outcome'] = bootstrapped_death_prob\n",
    "\n",
    "    simvalue = np.diff(simdata.groupby('group').mean().values.flatten())[0]\n",
    "    # since dead's are '1' and alive's are '0', the mean() function gets us the proportion of death\n",
    "    # (in each group, summing up the number of deaths and dividing by the number of crashes\n",
    "    # is our caculation for the proportion of deaths, but this is also the calculation for mean!)\n",
    "    simulated_values += [simvalue]\n",
    "\n",
    "calc_interval = tuple(np.round(np.quantile(simulated_values, (0.025, 0.975)), 5))\n",
    "assert calc_interval == interval, \"You got \" + str(interval) + \" for your 95% confidence interval but should be \" + str(calc_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df85ca3",
   "metadata": {},
   "source": [
    "## Type I and II Errors\n",
    "\n",
    "In the analyses of the previous week and this week you've used a quantiative p-value to provide a qualitative statement of the evidence against the *null hypothesis*. This doesn't necessarily entail a formal decision about a *null hypothesis* (and there are many good reasons to proceed in this manner). However, it would also be possible to make a statement about the *null hypothesis* which should ideally take the form of \"I choose to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand\", or contrarily \"I fail to reject the *null hypothesis*...\" \n",
    " \n",
    "In *formal statstical hypothesis testing*, wrongly rejecting a *null hypothesis* which is actually true is called a *type I error*; whereas, wrongly failing to reject a *null hypothesis* which is actually false is called a *type II error*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137c4f1",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q19: Make a statement about the null hypothesis based on your analysis above in Q17. What kind of error could you have made in your conclusion?\n",
    "A. I choose to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars with 'airbag' and with 'no-airbag' is actually the same, then we have made a Type I Error.  \n",
    "\n",
    "B. I choose to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars with 'airbag' and with 'no-airbag' is actually the same, then we have made a Type II Error.   \n",
    "\n",
    "C. I fail to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars with 'no-airbag' is actually more than cars with an 'airbag', then we have made a Type I Error.  \n",
    "\n",
    "D. I fail to reject the *null hypothesis* $H_0$ on the basis of the evidence at hand, so if the probability of death in crashes for cars with 'no-airbag' is actually more than cars with an 'airbag', then we have made a Type II Error.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cde3b390",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Q19: your answer will be tested!\n",
    "Q19 = None # Assign either 'A' or 'B' or 'C' or 'D' to `Q19` instead of `None`\n",
    "# E.g., Q19 = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc330028",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calc_p_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# test_Q19\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m hint \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou reported a p-value of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(p_value) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m (correct p-value was \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(calc_p_value) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m hint \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mand correspondingly\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m hint \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcharacterized this the evidence against the null hypothesis as option \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m evidence \n",
      "\u001b[1;31mNameError\u001b[0m: name 'calc_p_value' is not defined"
     ]
    }
   ],
   "source": [
    "# test_Q19\n",
    "\n",
    "hint = \"You reported a p-value of \" + str(p_value) + \" (correct p-value was \" + str(calc_p_value) + \") \"\n",
    "hint += \"and correspondingly\\n\"\n",
    "hint += \"characterized this the evidence against the null hypothesis as option \" + evidence \n",
    "hint += \"\\n(A: NONE; B: WEAK; C: MODERATE; D: STRONG; E: VERY STRONG).\\n\" \n",
    "hint += \"A p-value of \" + str(calc_p_value) + \" corresponds to \" +  evidence_choice_in_words[actually_correct_evidence_choice]\n",
    "hint += \" evidence against the null hypothesis\\n\"\n",
    "hint += \"So your characterization of evidence against the null hypothesis was \"\n",
    "hint += \"incorrect\"*(not evidence_test) + \"correct\"*(evidence_test) + \".\\n\\n\"\n",
    "hint += \"Assuming you did not choose to reject the null hypthesis if the evidence against it\\n\"\n",
    "hint += \"was WEAK or if there was NO evidence against the null hypthesis, then you could have\\n\"\n",
    "hint += \"made a type II error by failing to reject a false null hypothesis.\\n\"\n",
    "hint += \"This was not mean a type II error was made: it just means it could have been made.\\n\\n\"\n",
    "hint += \"Assuming you did choose to reject the null hypthesis if the evidence against it\\n\"\n",
    "hint += \"was MODERATE to VERY STRONG evidence against the null hypthesis, then you could have\\n\"\n",
    "hint += \"made a type I error by rejecting a true null hypothesis.\\n\"\n",
    "hint += \"This was not mean a type I error was made: it just means it could have been made.\"\n",
    "\n",
    "assert ((evidence=='A' or evidence=='B') and Q19 == 'D') or ((evidence!='A' and evidence!='B') and Q19 == 'A'), hint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ba201",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q20: Assuming your analysis has provided some evidence against the null hypothesis of no survival differences in car crashes between cars with and without airbags, are you ready to suggest and support the claim that this data supports the claim that \"airbags save lives\"? Explain how this data could be confounded by either (a) \"death wish\" drivers and (b) age in a manner that could produce the observed survival rate differences and therefore shed doubt on the claim that \"airbags save lives\" and discuss wheather or not you find entertaining each of these two possibilites compelling.\n",
    "\n",
    "> - Hint: In the \"Social Media and Anxiety\" problem we imagined that people who were already prone to anxiety might also be more likely to use social media with a higher frequency. What would be a story about (a) \"death wish drivers\" and (b) \"age\" that could cause people to both tend to drive cars without airbags and be more likely die in a car crash?\n",
    "\n",
    "#### Provide your written answer about four to six sentences in the markdown cell below.  \n",
    "- This will be manually reviewed by your TA.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b5e8d",
   "metadata": {
    "deletable": false
   },
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f8713",
   "metadata": {},
   "source": [
    "#### SAMPLE SOLUTION for TAs to share with poor solution answers\n",
    "\n",
    "The data does indeed appear to support the claim that \"airbags save lives\". \n",
    "But, a \"death wish\" driver intentionally choosing to drive a car without airbags while trying to get into a bad wreck in order to die would also seem to empirically support this claim if we didn't know the intentions of such a driver. It does seems unlikely, thought, that there would be a lot of \"death wish\" drivers skewing the data in this manner.\n",
    "However, if older people tend to drive cars without airbags because they have older cars, and if because they're older they're potentially more frail and more prone to die as a result of injuries, then this confounding could also make it appear as if \"airbags save lives\" when in fact the reason for the observed difference was not due to increased protection from airbags and instead just a result of this age confounding by. \n",
    "For this to be a compelling argument, we'd have to examine crash death rates by age, and we'd have to see if there are a large proportion of older people that could be imbalanced between driving cars with and without airbags. It seems, though, that the nature of the confounding that would cause such an effect would need to be pretty strong in order to account for the differences we're seeing without any positive safety effect of seatbelts themselves... so perhaps it is unlikely.  However, it does seem like something that could and should be checked with additional data..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 6
}
